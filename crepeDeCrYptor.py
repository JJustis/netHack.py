#!/usr/bin/env python3
"""
Legitimate Quantum Warp Drive Encryption (QWDE) Cryptanalysis
A real cryptanalysis attack that only uses publicly available information
and attempts to break the encryption through legitimate means.
"""

import random
import json
import time
import math
import struct
import hashlib
import pickle
import os
from typing import List, Dict, Tuple, Any, Optional
from collections import namedtuple, deque
from dataclasses import dataclass, field
from abc import ABC, abstractmethod

# Safe numpy import with fallback
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    print("Warning: NumPy not available. Neural network features will be limited.")
    NUMPY_AVAILABLE = False
    # Create minimal numpy-like interface for basic operations
    class SimpleNumPy:
        @staticmethod
        def array(data):
            return data
        
        @staticmethod
        def zeros(size):
            if isinstance(size, int):
                return [0.0] * size
            return [[0.0] * size[1] for _ in range(size[0])]
        
        @staticmethod
        def random_randn(*args):
            return [random.gauss(0, 1) for _ in range(args[0] if args else 1)]
        
        @staticmethod
        def mean(data):
            return sum(data) / len(data) if data else 0
        
        @staticmethod
        def std(data):
            if not data:
                return 0
            mean_val = sum(data) / len(data)
            variance = sum((x - mean_val) ** 2 for x in data) / len(data)
            return math.sqrt(variance)
    
    np = SimpleNumPy()

# Import all the original classes (WarpBubbleParams, PhysicsConstants, etc.)
@dataclass
class WarpBubbleParams:
    radius: float = 1.0           # Bubble radius (R)
    thickness: float = 0.1        # Wall thickness
    velocity: float = 0.5         # Velocity (v/c)
    exponent_n: int = 100         # Exponent n for metric
    causal_disconnect: float = 0.85  # Causal disconnection factor

@dataclass
class PhysicsConstants:
    SPEED_OF_LIGHT: float = 299792458        # m/s
    PLANCK_CONSTANT: float = 1.054571817e-34 # JÂ·s
    GRAVITATIONAL_CONSTANT: float = 6.67430e-11  # mÂ³/kgÂ·sÂ²

@dataclass
class QuantumMetrics:
    temporal_discontinuity: float = 0.0
    energy_density: float = 0.0
    quantum_entropy: float = 0.0
    quadrant_entropies: List[float] = None
    metric_fluctuation: float = 0.0
    density_fluctuation: float = 0.0

@dataclass
class QuadrantData:
    entropy: float
    causal_isolation: float
    quantum_state: np.ndarray
    fluctuation_amplitude: float

PrivateKey = namedtuple('PrivateKey', ['causal_params', 'temporal_params', 'prime', 'security_level', 'warp_params', 'causal_elements'])
PublicKey = namedtuple('PublicKey', ['causal_elements', 'temporal_elements', 'prime', 'generator', 'security_level', 'warp_metrics'])
KeyPair = namedtuple('KeyPair', ['private_key', 'public_key'])
Ciphertext = namedtuple('Ciphertext', ['quadrant_data', 'temporal_data', 'warp_signature'])

@dataclass
class AttackResult:
    success: bool
    decrypted_message: str
    plaintext_accuracy: float
    key_guess: Any
    decryption_method: str
    confidence: float

@dataclass
class TrainingData:
    """Comprehensive training data for AI persistence."""
    neural_training_history: List[Tuple[List[float], float]] = field(default_factory=list)
    genetic_populations: List[Dict] = field(default_factory=list)
    successful_parameters: List[Dict] = field(default_factory=list)
    attack_patterns: Dict[str, List[float]] = field(default_factory=dict)
    strategy_effectiveness: Dict[str, float] = field(default_factory=dict)
    breakthrough_history: List[Dict] = field(default_factory=list)
    convergence_patterns: List[float] = field(default_factory=list)
    parameter_correlations: Dict[str, float] = field(default_factory=dict)
    session_count: int = 0
    total_training_time: float = 0.0
    version: str = "1.0"

@dataclass
class AdvancedLearningMetrics:
    neural_confidence: float = 0.0
    genetic_fitness: float = 0.0
    clustering_coherence: float = 0.0
    correlation_strength: float = 0.0
    transfer_learning_boost: float = 0.0
    ensemble_consensus: float = 0.0
    exploration_efficiency: float = 0.0
    convergence_velocity: float = 0.0
    reinforcement_q_value: float = 0.0
    swarm_convergence: float = 0.0

@dataclass
class ReinforcementState:
    """State representation for RL attack."""
    current_accuracy: float
    attempts_made: int
    parameter_vector: List[float]
    recent_improvements: List[float]
    strategy_history: List[str]

@dataclass
class ParticleState:
    """Particle state for swarm intelligence."""
    position: List[float]  # Current warp parameters
    velocity: List[float]  # Parameter change velocity
    best_position: List[float]  # Personal best position
    best_accuracy: float  # Personal best accuracy
    fitness: float  # Current fitness value

class AITrainingSystem:
    """Advanced AI training system with persistence and pre-trained intelligence."""
    
    def __init__(self, training_file: str = "quantum_ai_training.pkl"):
        self.training_file = training_file
        self.training_data = TrainingData()
        self.is_loaded = False
        
    def load_training_data(self) -> bool:
        """Load pre-trained AI intelligence from file."""
        try:
            if os.path.exists(self.training_file):
                with open(self.training_file, 'rb') as f:
                    self.training_data = pickle.load(f)
                self.is_loaded = True
                print(f"ðŸ§  Loaded AI training data: {self.training_data.session_count} sessions, "
                      f"{len(self.training_data.successful_parameters)} successful patterns")
                return True
            else:
                print(f"ðŸ†• No existing training data found - starting fresh")
                return False
        except Exception as e:
            print(f"âš ï¸ Error loading training data: {e}")
            return False
    
    def save_training_data(self) -> bool:
        """Save AI training data for future sessions."""
        try:
            self.training_data.session_count += 1
            with open(self.training_file, 'wb') as f:
                pickle.dump(self.training_data, f)
            print(f"ðŸ’¾ Saved AI training data: Session #{self.training_data.session_count}")
            return True
        except Exception as e:
            print(f"âš ï¸ Error saving training data: {e}")
            return False
    
    def add_training_sample(self, features: List[float], accuracy: float):
        """Add training sample to neural network history."""
        self.training_data.neural_training_history.append((features, accuracy))
        # Keep only recent samples to prevent memory bloat
        if len(self.training_data.neural_training_history) > 10000:
            self.training_data.neural_training_history = self.training_data.neural_training_history[-5000:]
    
    def add_successful_parameter(self, warp_params: WarpBubbleParams, accuracy: float, method: str):
        """Add successful parameter combination to knowledge base."""
        param_dict = {
            'radius': warp_params.radius,
            'thickness': warp_params.thickness,
            'velocity': warp_params.velocity,
            'exponent_n': warp_params.exponent_n,
            'causal_disconnect': warp_params.causal_disconnect,
            'accuracy': accuracy,
            'method': method,
            'timestamp': time.time()
        }
        self.training_data.successful_parameters.append(param_dict)
        
        # Update strategy effectiveness
        if method not in self.training_data.strategy_effectiveness:
            self.training_data.strategy_effectiveness[method] = []
        if isinstance(self.training_data.strategy_effectiveness[method], list):
            self.training_data.strategy_effectiveness[method] = []
        self.training_data.strategy_effectiveness[method] = accuracy
    
    def get_successful_patterns(self, top_n: int = 50) -> List[WarpBubbleParams]:
        """Get top successful parameter patterns from training history."""
        if not self.training_data.successful_parameters:
            return []
        
        # Sort by accuracy and return top patterns
        sorted_params = sorted(self.training_data.successful_parameters, 
                             key=lambda x: x['accuracy'], reverse=True)
        
        patterns = []
        for param_dict in sorted_params[:top_n]:
            patterns.append(WarpBubbleParams(
                radius=param_dict['radius'],
                thickness=param_dict['thickness'],
                velocity=param_dict['velocity'],
                exponent_n=param_dict['exponent_n'],
                causal_disconnect=param_dict['causal_disconnect']
            ))
        
        return patterns
    
    def get_strategy_weights(self) -> Dict[str, float]:
        """Get pre-trained strategy effectiveness weights."""
        if not self.training_data.strategy_effectiveness:
            return {}
        
        # Normalize weights
        total = sum(self.training_data.strategy_effectiveness.values())
        if total > 0:
            return {k: v/total for k, v in self.training_data.strategy_effectiveness.items()}
        return {}

class ReinforcementLearningAttack:
    """Q-Learning based reinforcement learning attack."""
    
    def __init__(self, training_system: AITrainingSystem):
        self.training_system = training_system
        self.q_table = {}  # State-action Q values
        self.learning_rate = 0.1
        self.discount_factor = 0.95
        self.epsilon = 0.1  # Exploration rate
        self.action_space = [
            'increase_radius', 'decrease_radius',
            'increase_velocity', 'decrease_velocity', 
            'increase_thickness', 'decrease_thickness',
            'increase_exponent', 'decrease_exponent',
            'increase_causal', 'decrease_causal',
            'random_jump', 'local_search'
        ]
        self.state_history = deque(maxlen=100)
        self.reward_history = []
        
    def state_to_key(self, state: ReinforcementState) -> str:
        """Convert state to hashable key."""
        # Discretize continuous values for Q-table
        acc_bucket = int(state.current_accuracy * 10)  # 0-10 buckets
        attempts_bucket = min(int(state.attempts_made / 100), 10)  # 0-10 buckets
        param_signature = hash(tuple(int(p * 100) % 100 for p in state.parameter_vector[:3]))
        
        return f"{acc_bucket}_{attempts_bucket}_{param_signature}"
    
    def get_state(self, warp_params: WarpBubbleParams, accuracy: float, attempts: int) -> ReinforcementState:
        """Create state representation from current situation."""
        param_vector = [
            warp_params.radius / 5.0,  # Normalize to 0-1
            warp_params.thickness / 0.5,
            warp_params.velocity,
            warp_params.exponent_n / 500.0,
            warp_params.causal_disconnect
        ]
        
        recent_improvements = []
        if len(self.reward_history) >= 5:
            recent_improvements = self.reward_history[-5:]
        
        return ReinforcementState(
            current_accuracy=accuracy,
            attempts_made=attempts,
            parameter_vector=param_vector,
            recent_improvements=recent_improvements,
            strategy_history=[]
        )
    
    def choose_action(self, state: ReinforcementState) -> str:
        """Choose action using epsilon-greedy policy."""
        state_key = self.state_to_key(state)
        
        # Exploration vs exploitation
        if random.random() < self.epsilon or state_key not in self.q_table:
            return random.choice(self.action_space)
        
        # Choose best action from Q-table
        q_values = self.q_table[state_key]
        return max(q_values.items(), key=lambda x: x[1])[0]
    
    def apply_action(self, action: str, warp_params: WarpBubbleParams) -> WarpBubbleParams:
        """Apply RL action to modify parameters."""
        step_size = 0.1
        
        # Create new parameters by copying and modifying
        radius = warp_params.radius
        thickness = warp_params.thickness
        velocity = warp_params.velocity
        exponent_n = warp_params.exponent_n
        causal_disconnect = warp_params.causal_disconnect
        
        if action == 'increase_radius':
            radius = min(5.0, warp_params.radius + step_size)
        elif action == 'decrease_radius':
            radius = max(0.1, warp_params.radius - step_size)
        elif action == 'increase_velocity':
            velocity = min(0.99, warp_params.velocity + step_size)
        elif action == 'decrease_velocity':
            velocity = max(0.01, warp_params.velocity - step_size)
        elif action == 'increase_thickness':
            thickness = min(0.5, warp_params.thickness + step_size * 0.1)
        elif action == 'decrease_thickness':
            thickness = max(0.01, warp_params.thickness - step_size * 0.1)
        elif action == 'increase_exponent':
            exponent_n = min(500, warp_params.exponent_n + 10)
        elif action == 'decrease_exponent':
            exponent_n = max(10, warp_params.exponent_n - 10)
        elif action == 'increase_causal':
            causal_disconnect = min(0.99, warp_params.causal_disconnect + step_size * 0.1)
        elif action == 'decrease_causal':
            causal_disconnect = max(0.5, warp_params.causal_disconnect - step_size * 0.1)
        elif action == 'random_jump':
            # Large random change
            return WarpBubbleParams(
                radius=random.uniform(0.5, 3.0),
                thickness=random.uniform(0.05, 0.2),
                velocity=random.uniform(0.1, 0.9),
                exponent_n=random.randint(50, 200),
                causal_disconnect=random.uniform(0.7, 0.95)
            )
        elif action == 'local_search':
            # Small random perturbation
            return WarpBubbleParams(
                radius=max(0.1, min(5.0, warp_params.radius + random.uniform(-0.05, 0.05))),
                thickness=max(0.01, min(0.5, warp_params.thickness + random.uniform(-0.005, 0.005))),
                velocity=max(0.01, min(0.99, warp_params.velocity + random.uniform(-0.02, 0.02))),
                exponent_n=max(10, min(500, warp_params.exponent_n + random.randint(-5, 5))),
                causal_disconnect=max(0.5, min(0.99, warp_params.causal_disconnect + random.uniform(-0.01, 0.01)))
            )
        
        # Return new WarpBubbleParams with modified values
        return WarpBubbleParams(
            radius=radius,
            thickness=thickness,
            velocity=velocity,
            exponent_n=exponent_n,
            causal_disconnect=causal_disconnect
        )
    
    def update_q_value(self, state: ReinforcementState, action: str, reward: float, next_state: ReinforcementState):
        """Update Q-value using Q-learning algorithm."""
        state_key = self.state_to_key(state)
        next_state_key = self.state_to_key(next_state)
        
        # Initialize Q-table entries if needed
        if state_key not in self.q_table:
            self.q_table[state_key] = {a: 0.0 for a in self.action_space}
        if next_state_key not in self.q_table:
            self.q_table[next_state_key] = {a: 0.0 for a in self.action_space}
        
        # Q-learning update
        current_q = self.q_table[state_key][action]
        max_next_q = max(self.q_table[next_state_key].values())
        
        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)
        self.q_table[state_key][action] = new_q
        
        # Store reward for tracking
        self.reward_history.append(reward)
        if len(self.reward_history) > 1000:
            self.reward_history = self.reward_history[-500:]
    
    def generate_parameters(self, current_params: WarpBubbleParams, current_accuracy: float, attempts: int) -> Tuple[WarpBubbleParams, str]:
        """Generate new parameters using reinforcement learning."""
        state = self.get_state(current_params, current_accuracy, attempts)
        action = self.choose_action(state)
        new_params = self.apply_action(action, current_params)
        
        return new_params, f"reinforcement_learning_{action}"
    
    def learn_from_result(self, old_params: WarpBubbleParams, old_accuracy: float, 
                         new_params: WarpBubbleParams, new_accuracy: float, attempts: int):
        """Learn from attack result."""
        # Calculate reward based on accuracy improvement
        reward = (new_accuracy - old_accuracy) * 10  # Scale reward
        if new_accuracy > 0.9:
            reward += 10  # Bonus for high accuracy
        elif new_accuracy > 0.5:
            reward += 5
        
        old_state = self.get_state(old_params, old_accuracy, attempts - 1)
        new_state = self.get_state(new_params, new_accuracy, attempts)
        
        # We need to store the action that was taken
        # For now, we'll use a simple heuristic to infer the action
        action = self.infer_action(old_params, new_params)
        
        self.update_q_value(old_state, action, reward, new_state)
    
    def infer_action(self, old_params: WarpBubbleParams, new_params: WarpBubbleParams) -> str:
        """Infer which action was likely taken based on parameter changes."""
        if abs(new_params.radius - old_params.radius) > 0.05:
            return 'increase_radius' if new_params.radius > old_params.radius else 'decrease_radius'
        elif abs(new_params.velocity - old_params.velocity) > 0.05:
            return 'increase_velocity' if new_params.velocity > old_params.velocity else 'decrease_velocity'
        elif abs(new_params.thickness - old_params.thickness) > 0.005:
            return 'increase_thickness' if new_params.thickness > old_params.thickness else 'decrease_thickness'
        elif abs(new_params.exponent_n - old_params.exponent_n) > 5:
            return 'increase_exponent' if new_params.exponent_n > old_params.exponent_n else 'decrease_exponent'
        elif abs(new_params.causal_disconnect - old_params.causal_disconnect) > 0.01:
            return 'increase_causal' if new_params.causal_disconnect > old_params.causal_disconnect else 'decrease_causal'
        else:
            return 'local_search'

class SwarmIntelligenceAttack:
    """Particle Swarm Optimization attack for parameter space exploration."""
    
    def __init__(self, training_system: AITrainingSystem, swarm_size: int = 30):
        self.training_system = training_system
        self.swarm_size = swarm_size
        self.particles: List[ParticleState] = []
        self.global_best_position: List[float] = []
        self.global_best_accuracy: float = 0.0
        self.inertia_weight = 0.9
        self.cognitive_weight = 2.0
        self.social_weight = 2.0
        self.generation = 0
        
        self.initialize_swarm()
    
    def initialize_swarm(self):
        """Initialize particle swarm."""
        self.particles = []
        
        # Load successful patterns from training if available
        successful_patterns = self.training_system.get_successful_patterns(top_n=10)
        
        for i in range(self.swarm_size):
            if i < len(successful_patterns) and successful_patterns:
                # Initialize some particles around successful patterns
                pattern = successful_patterns[i % len(successful_patterns)]
                position = [
                    pattern.radius + random.uniform(-0.2, 0.2),
                    pattern.thickness + random.uniform(-0.02, 0.02),
                    pattern.velocity + random.uniform(-0.1, 0.1),
                    pattern.exponent_n + random.uniform(-20, 20),
                    pattern.causal_disconnect + random.uniform(-0.05, 0.05)
                ]
            else:
                # Random initialization
                position = [
                    random.uniform(0.5, 3.0),      # radius
                    random.uniform(0.05, 0.2),     # thickness
                    random.uniform(0.1, 0.9),      # velocity
                    random.uniform(50, 200),       # exponent_n
                    random.uniform(0.7, 0.95)      # causal_disconnect
                ]
            
            velocity = [random.uniform(-0.1, 0.1) for _ in range(5)]
            
            particle = ParticleState(
                position=position,
                velocity=velocity,
                best_position=position.copy(),
                best_accuracy=0.0,
                fitness=0.0
            )
            
            self.particles.append(particle)
    
    def position_to_warp_params(self, position: List[float]) -> WarpBubbleParams:
        """Convert particle position to warp parameters."""
        return WarpBubbleParams(
            radius=max(0.1, min(5.0, position[0])),
            thickness=max(0.01, min(0.5, position[1])),
            velocity=max(0.01, min(0.99, position[2])),
            exponent_n=max(10, min(500, int(position[3]))),
            causal_disconnect=max(0.5, min(0.99, position[4]))
        )
    
    def update_particle_velocity(self, particle: ParticleState):
        """Update particle velocity using PSO algorithm."""
        for i in range(len(particle.velocity)):
            # Inertia component
            inertia = self.inertia_weight * particle.velocity[i]
            
            # Cognitive component (personal best)
            cognitive = (self.cognitive_weight * random.random() * 
                        (particle.best_position[i] - particle.position[i]))
            
            # Social component (global best)
            social = 0.0
            if self.global_best_position:
                social = (self.social_weight * random.random() * 
                         (self.global_best_position[i] - particle.position[i]))
            
            # Update velocity
            particle.velocity[i] = inertia + cognitive + social
            
            # Clamp velocity to reasonable bounds
            max_velocity = 0.2
            particle.velocity[i] = max(-max_velocity, min(max_velocity, particle.velocity[i]))
    
    def update_particle_position(self, particle: ParticleState):
        """Update particle position."""
        for i in range(len(particle.position)):
            particle.position[i] += particle.velocity[i]
        
        # Ensure position stays within bounds
        particle.position[0] = max(0.1, min(5.0, particle.position[0]))      # radius
        particle.position[1] = max(0.01, min(0.5, particle.position[1]))     # thickness  
        particle.position[2] = max(0.01, min(0.99, particle.position[2]))    # velocity
        particle.position[3] = max(10, min(500, particle.position[3]))       # exponent_n
        particle.position[4] = max(0.5, min(0.99, particle.position[4]))     # causal_disconnect
    
    def evaluate_particle(self, particle: ParticleState, accuracy: float):
        """Evaluate particle fitness and update personal/global bests."""
        particle.fitness = accuracy
        
        # Update personal best
        if accuracy > particle.best_accuracy:
            particle.best_accuracy = accuracy
            particle.best_position = particle.position.copy()
        
        # Update global best
        if accuracy > self.global_best_accuracy:
            self.global_best_accuracy = accuracy
            self.global_best_position = particle.position.copy()
    
    def get_best_particle(self) -> ParticleState:
        """Get the particle with best fitness."""
        return max(self.particles, key=lambda p: p.fitness)
    
    def evolve_swarm(self):
        """Evolve the swarm for one generation."""
        for particle in self.particles:
            self.update_particle_velocity(particle)
            self.update_particle_position(particle)
        
        self.generation += 1
        
        # Decrease inertia weight over time for better convergence
        self.inertia_weight = max(0.4, 0.9 - self.generation * 0.01)
    
    def generate_parameters(self) -> Tuple[WarpBubbleParams, str]:
        """Generate parameters using particle swarm optimization."""
        # Choose a particle (prefer better particles but allow exploration)
        if random.random() < 0.7:  # 70% chance to use better particles
            weights = [p.fitness + 0.1 for p in self.particles]  # Add small base weight
            particle = random.choices(self.particles, weights=weights, k=1)[0]
        else:
            particle = random.choice(self.particles)
        
        warp_params = self.position_to_warp_params(particle.position)
        return warp_params, f"swarm_intelligence_gen{self.generation}"
    
    def learn_from_result(self, warp_params: WarpBubbleParams, accuracy: float):
        """Learn from attack result."""
        # Find the particle closest to these parameters
        param_vector = [warp_params.radius, warp_params.thickness, warp_params.velocity, 
                       warp_params.exponent_n, warp_params.causal_disconnect]
        
        closest_particle = min(self.particles, 
                              key=lambda p: sum((p.position[i] - param_vector[i])**2 for i in range(5)))
        
        # Evaluate and update this particle
        self.evaluate_particle(closest_particle, accuracy)
        
        # Evolve swarm occasionally
        if random.random() < 0.1:  # 10% chance to evolve
            self.evolve_swarm()
    neural_confidence: float = 0.0
    genetic_fitness: float = 0.0
    clustering_coherence: float = 0.0
    correlation_strength: float = 0.0
    transfer_learning_boost: float = 0.0
    ensemble_consensus: float = 0.0
    exploration_efficiency: float = 0.0
    convergence_velocity: float = 0.0

@dataclass
class ParameterGenome:
    """Genetic representation of warp parameters for evolutionary algorithms."""
    genes: List[float]  # [radius, thickness, velocity, exponent_n, causal_disconnect]
    fitness: float = 0.0
    generation: int = 0
    parent_ids: List[int] = None
    mutation_rate: float = 0.1
    
    def to_warp_params(self) -> WarpBubbleParams:
        """Convert genetic representation to warp parameters."""
        return WarpBubbleParams(
            radius=max(0.1, min(5.0, self.genes[0])),
            thickness=max(0.01, min(0.5, self.genes[1])),
            velocity=max(0.01, min(0.99, self.genes[2])),
            exponent_n=max(10, min(500, int(self.genes[3]))),
            causal_disconnect=max(0.5, min(0.99, self.genes[4]))
        )

class AdvancedNeuralLearner:
    """Neural network that learns warp parameter patterns."""
    
    def __init__(self):
        if NUMPY_AVAILABLE:
            # Input: 15 features (5 warp params + 10 derived features)
            # Hidden: 64, 32, 16 neurons
            # Output: 5 optimized warp parameters
            self.network = self.create_neural_network()
            self.training_data = []
            self.prediction_accuracy = 0.0
        else:
            self.network = None
            self.training_data = []
            self.prediction_accuracy = 0.0
    
    def create_neural_network(self):
        """Create a sophisticated neural network for parameter learning."""
        if not NUMPY_AVAILABLE:
            return None
        
        # Simplified network structure for the fallback implementation
        return {
            'weights1': np.random.randn(15, 64) * 0.1,
            'bias1': np.zeros(64),
            'weights2': np.random.randn(64, 32) * 0.1,
            'bias2': np.zeros(32),
            'weights3': np.random.randn(32, 5) * 0.1,
            'bias3': np.zeros(5)
        }
    
    def extract_features(self, warp_params: WarpBubbleParams, accuracy: float) -> List[float]:
        """Extract comprehensive features from warp parameters and results."""
        features = [
            warp_params.radius,
            warp_params.thickness,
            warp_params.velocity,
            float(warp_params.exponent_n) / 500.0,  # Normalize
            warp_params.causal_disconnect,
            # Derived features
            warp_params.radius * warp_params.velocity,  # Interaction term
            warp_params.thickness / warp_params.radius,  # Aspect ratio
            math.log(warp_params.exponent_n + 1) / 10.0,  # Log-scaled exponent
            warp_params.causal_disconnect ** 2,  # Nonlinear transform
            (warp_params.velocity ** 2) * warp_params.causal_disconnect,  # Complex interaction
            # Physics-based features
            1.0 / (warp_params.radius ** 2),  # Inverse square law
            warp_params.velocity * warp_params.causal_disconnect,  # Causal velocity
            math.sin(warp_params.exponent_n * 0.1),  # Periodic component
            warp_params.thickness * warp_params.velocity,  # Wall dynamics
            accuracy  # Target feedback
        ]
        return features
    
    def learn(self, warp_params: WarpBubbleParams, accuracy: float) -> float:
        """Learn from a parameter-accuracy pair."""
        features = self.extract_features(warp_params, accuracy)
        self.training_data.append((features[:-1], features[-1]))  # Exclude accuracy from input
        
        # Simplified learning update
        if len(self.training_data) > 10:
            # Calculate prediction accuracy improvement
            recent_accuracies = [data[1] for data in self.training_data[-10:]]
            self.prediction_accuracy = np.mean(recent_accuracies) if NUMPY_AVAILABLE else sum(recent_accuracies) / len(recent_accuracies)
        
        return self.prediction_accuracy
    
    def predict_optimal_params(self, current_best: WarpBubbleParams = None) -> WarpBubbleParams:
        """Predict optimal parameters using learned patterns."""
        if len(self.training_data) < 5:
            # Not enough data, return random guess
            return WarpBubbleParams(
                radius=random.uniform(0.5, 3.0),
                thickness=random.uniform(0.05, 0.2),
                velocity=random.uniform(0.1, 0.9),
                exponent_n=random.randint(50, 200),
                causal_disconnect=random.uniform(0.7, 0.95)
            )
        
        # Find best parameters from training data
        best_data = max(self.training_data, key=lambda x: x[1])
        best_features = best_data[0]
        
        # Apply learned optimizations
        optimized_params = WarpBubbleParams(
            radius=best_features[0] + random.uniform(-0.1, 0.1),
            thickness=best_features[1] + random.uniform(-0.01, 0.01),
            velocity=best_features[2] + random.uniform(-0.05, 0.05),
            exponent_n=int(best_features[3] * 500 + random.uniform(-10, 10)),
            causal_disconnect=best_features[4] + random.uniform(-0.02, 0.02)
        )
        
        return optimized_params

class GeneticParameterEvolution:
    """Genetic algorithm for evolving optimal warp parameters."""
    
    def __init__(self, population_size: int = 50):
        self.population_size = population_size
        self.population: List[ParameterGenome] = []
        self.generation = 0
        self.best_genome = None
        self.fitness_history = []
        
    def initialize_population(self) -> None:
        """Initialize random population of parameter genomes."""
        self.population = []
        for i in range(self.population_size):
            genes = [
                random.uniform(0.5, 3.0),      # radius
                random.uniform(0.05, 0.2),     # thickness
                random.uniform(0.1, 0.9),      # velocity
                random.uniform(50, 200),       # exponent_n
                random.uniform(0.7, 0.95)      # causal_disconnect
            ]
            genome = ParameterGenome(genes=genes, generation=0, parent_ids=[])
            self.population.append(genome)
    
    def evaluate_fitness(self, genome: ParameterGenome, accuracy: float) -> None:
        """Evaluate and update genome fitness."""
        # Fitness is combination of accuracy and parameter stability
        stability_bonus = 1.0 - (abs(genome.genes[0] - 1.5) / 2.0)  # Prefer radius near 1.5
        genome.fitness = accuracy * 0.8 + stability_bonus * 0.2
        
        if self.best_genome is None or genome.fitness > self.best_genome.fitness:
            self.best_genome = genome
    
    def selection(self) -> List[ParameterGenome]:
        """Tournament selection for breeding."""
        selected = []
        tournament_size = 5
        
        for _ in range(self.population_size // 2):
            tournament = random.sample(self.population, tournament_size)
            winner = max(tournament, key=lambda g: g.fitness)
            selected.append(winner)
        
        return selected
    
    def crossover(self, parent1: ParameterGenome, parent2: ParameterGenome) -> ParameterGenome:
        """Create offspring through crossover."""
        # Uniform crossover
        child_genes = []
        for i in range(len(parent1.genes)):
            if random.random() < 0.5:
                child_genes.append(parent1.genes[i])
            else:
                child_genes.append(parent2.genes[i])
        
        child = ParameterGenome(
            genes=child_genes,
            generation=self.generation + 1,
            parent_ids=[id(parent1), id(parent2)]
        )
        return child
    
    def mutate(self, genome: ParameterGenome) -> ParameterGenome:
        """Apply mutation to genome."""
        mutation_ranges = [0.2, 0.02, 0.1, 20, 0.05]  # Different ranges for each gene
        
        for i in range(len(genome.genes)):
            if random.random() < genome.mutation_rate:
                mutation = random.uniform(-mutation_ranges[i], mutation_ranges[i])
                genome.genes[i] += mutation
        
        return genome
    
    def evolve_generation(self) -> ParameterGenome:
        """Evolve one generation and return best candidate."""
        if not self.population:
            self.initialize_population()
        
        # Selection
        parents = self.selection()
        
        # Create new generation
        new_population = []
        
        # Elitism - keep best genomes
        elite_count = max(1, self.population_size // 10)
        elite = sorted(self.population, key=lambda g: g.fitness, reverse=True)[:elite_count]
        new_population.extend(elite)
        
        # Generate offspring
        while len(new_population) < self.population_size:
            parent1, parent2 = random.sample(parents, 2)
            child = self.crossover(parent1, parent2)
            child = self.mutate(child)
            new_population.append(child)
        
        self.population = new_population
        self.generation += 1
        
        # Return best candidate for testing
        if self.best_genome:
            return self.best_genome
        else:
            return random.choice(self.population)

class ParameterClusterAnalyzer:
    """Analyzes clusters of successful parameters to find patterns."""
    
    def __init__(self):
        self.successful_params = []
        self.clusters = []
        self.cluster_centers = []
        
    def add_successful_params(self, warp_params: WarpBubbleParams, accuracy: float) -> None:
        """Add successful parameters to analysis."""
        if accuracy > 0.1:  # Only consider reasonably successful attempts
            param_vector = [
                warp_params.radius,
                warp_params.thickness,
                warp_params.velocity,
                float(warp_params.exponent_n) / 500.0,
                warp_params.causal_disconnect,
                accuracy
            ]
            self.successful_params.append(param_vector)
    
    def analyze_clusters(self) -> List[WarpBubbleParams]:
        """Analyze parameter clusters and return cluster centers."""
        if len(self.successful_params) < 10:
            return []
        
        # Simple k-means clustering (simplified implementation)
        k = min(5, len(self.successful_params) // 3)
        
        # Initialize cluster centers randomly
        self.cluster_centers = random.sample(self.successful_params, k)
        
        # Simple clustering iterations
        for _ in range(10):
            clusters = [[] for _ in range(k)]
            
            # Assign points to nearest cluster
            for param in self.successful_params:
                distances = []
                for center in self.cluster_centers:
                    dist = sum((p - c) ** 2 for p, c in zip(param[:5], center[:5]))
                    distances.append(dist)
                
                nearest_cluster = distances.index(min(distances))
                clusters[nearest_cluster].append(param)
            
            # Update cluster centers
            for i, cluster in enumerate(clusters):
                if cluster:
                    new_center = [sum(param[j] for param in cluster) / len(cluster) for j in range(6)]
                    self.cluster_centers[i] = new_center
        
        # Convert cluster centers back to WarpBubbleParams
        result = []
        for center in self.cluster_centers:
            if center:  # Ensure center is not empty
                params = WarpBubbleParams(
                    radius=center[0],
                    thickness=center[1],
                    velocity=center[2],
                    exponent_n=int(center[3] * 500),
                    causal_disconnect=center[4]
                )
                result.append(params)
        
        return result

class TransferLearningEngine:
    """Learns from previous attack sessions to accelerate future attacks."""
    
    def __init__(self):
        self.knowledge_base = {
            'successful_patterns': [],
            'failed_patterns': [],
            'convergence_strategies': [],
            'parameter_correlations': {}
        }
        self.transfer_boost = 0.0
    
    def store_attack_knowledge(self, attack_history: List[Dict]) -> None:
        """Store knowledge from completed attacks."""
        for result in attack_history:
            if result.get('plaintext_accuracy', 0) > 0.5:
                pattern = {
                    'params': result['key_guess'].warp_params,
                    'accuracy': result['plaintext_accuracy'],
                    'method': result['decryption_method']
                }
                self.knowledge_base['successful_patterns'].append(pattern)
    
    def get_transfer_suggestions(self) -> List[WarpBubbleParams]:
        """Get parameter suggestions based on transferred knowledge."""
        suggestions = []
        
        # Use successful patterns from previous attacks
        for pattern in self.knowledge_base['successful_patterns'][-10:]:  # Last 10 successful
            # Create variations around successful parameters
            base_params = pattern['params']
            for _ in range(3):  # 3 variations per successful pattern
                variation = WarpBubbleParams(
                    radius=base_params.radius + random.uniform(-0.1, 0.1),
                    thickness=base_params.thickness + random.uniform(-0.01, 0.01),
                    velocity=base_params.velocity + random.uniform(-0.05, 0.05),
                    exponent_n=base_params.exponent_n + random.randint(-5, 5),
                    causal_disconnect=base_params.causal_disconnect + random.uniform(-0.02, 0.02)
                )
                suggestions.append(variation)
        
        return suggestions

class EnsembleAttackCoordinator:
    """Coordinates multiple attack strategies for maximum effectiveness with AI training."""
    
    def __init__(self):
        # Initialize training system and load pre-trained intelligence
        self.training_system = AITrainingSystem()
        self.training_system.load_training_data()
        
        # Initialize all AI attack methods
        self.neural_learner = AdvancedNeuralLearner()
        self.genetic_evolution = GeneticParameterEvolution()
        self.cluster_analyzer = ParameterClusterAnalyzer()
        self.transfer_engine = TransferLearningEngine()
        self.reinforcement_learner = ReinforcementLearningAttack(self.training_system)
        self.swarm_intelligence = SwarmIntelligenceAttack(self.training_system)
        
        # Strategy weights (will be updated from training data)
        self.strategy_weights = {
            'neural': 0.16,
            'genetic': 0.16, 
            'cluster': 0.16,
            'transfer': 0.16,
            'reinforcement': 0.18,  # Slightly higher for RL
            'swarm': 0.18           # Slightly higher for swarm
        }
        
        # Load pre-trained strategy weights if available
        trained_weights = self.training_system.get_strategy_weights()
        if trained_weights:
            self.strategy_weights.update(trained_weights)
            print(f"ðŸ§  Loaded pre-trained strategy weights from {self.training_system.training_data.session_count} sessions")
        
        self.performance_history = {
            'neural': [],
            'genetic': [],
            'cluster': [],
            'transfer': [],
            'reinforcement': [],
            'swarm': []
        }
        
        # Load successful patterns into transfer engine
        successful_patterns = self.training_system.get_successful_patterns()
        if successful_patterns:
            self.transfer_engine.knowledge_base['successful_patterns'] = [
                {'params': pattern, 'accuracy': 0.8, 'method': 'loaded'} 
                for pattern in successful_patterns[:20]
            ]
            print(f"ðŸ”„ Loaded {len(successful_patterns)} successful patterns for transfer learning")
    
    def update_strategy_weights(self) -> None:
        """Adaptively update strategy weights based on performance."""
        if all(len(history) > 5 for history in self.performance_history.values()):
            # Calculate recent performance for each strategy
            recent_performance = {}
            for strategy, history in self.performance_history.items():
                recent_performance[strategy] = np.mean(history[-5:]) if NUMPY_AVAILABLE else sum(history[-5:]) / 5
            
            # Softmax normalization with temperature
            temperature = 2.0  # Controls exploration vs exploitation
            if NUMPY_AVAILABLE:
                exp_values = np.exp(np.array(list(recent_performance.values())) / temperature)
                total = np.sum(exp_values)
                normalized = exp_values / total
                
                for i, strategy in enumerate(self.strategy_weights.keys()):
                    self.strategy_weights[strategy] = normalized[i]
            else:
                # Simple normalization fallback
                total = sum(recent_performance.values())
                if total > 0:
                    for strategy in self.strategy_weights:
                        self.strategy_weights[strategy] = recent_performance[strategy] / total
    
    def generate_ensemble_parameters(self) -> Tuple[WarpBubbleParams, str]:
        """Generate parameters using ensemble of strategies with pre-trained intelligence."""
        # Choose strategy based on weights
        strategy_choice = random.choices(
            list(self.strategy_weights.keys()),
            weights=list(self.strategy_weights.values()),
            k=1
        )[0]
        
        if strategy_choice == 'neural':
            params = self.neural_learner.predict_optimal_params()
            method = 'neural_prediction'
        elif strategy_choice == 'genetic':
            genome = self.genetic_evolution.evolve_generation()
            params = genome.to_warp_params()
            method = 'genetic_evolution'
        elif strategy_choice == 'cluster':
            cluster_centers = self.cluster_analyzer.analyze_clusters()
            if cluster_centers:
                params = random.choice(cluster_centers)
                method = 'cluster_analysis'
            else:
                params = self.neural_learner.predict_optimal_params()
                method = 'cluster_fallback'
        elif strategy_choice == 'transfer':
            suggestions = self.transfer_engine.get_transfer_suggestions()
            if suggestions:
                params = random.choice(suggestions)
                method = 'transfer_learning'
            else:
                params = self.neural_learner.predict_optimal_params()
                method = 'transfer_fallback'
        elif strategy_choice == 'reinforcement':
            # For first attempt, use random params, then RL will take over
            if not hasattr(self, '_rl_last_params'):
                self._rl_last_params = WarpBubbleParams()
                self._rl_last_accuracy = 0.0
                self._rl_attempts = 0
            
            params, method = self.reinforcement_learner.generate_parameters(
                self._rl_last_params, self._rl_last_accuracy, self._rl_attempts
            )
            self._rl_attempts += 1
        else:  # swarm
            params, method = self.swarm_intelligence.generate_parameters()
        
        return params, method
    
    def learn_from_result(self, warp_params: WarpBubbleParams, accuracy: float, method: str) -> AdvancedLearningMetrics:
        """Update all learning systems with new result."""
        # Save to training system for persistence
        self.training_system.add_successful_parameter(warp_params, accuracy, method)
        
        # Update individual learners
        neural_confidence = self.neural_learner.learn(warp_params, accuracy)
        
        # Update genetic algorithm
        if method.startswith('genetic') and self.genetic_evolution.population:
            # Find the genome that generated these parameters
            for genome in self.genetic_evolution.population:
                test_params = genome.to_warp_params()
                if (abs(test_params.radius - warp_params.radius) < 0.01 and
                    abs(test_params.velocity - warp_params.velocity) < 0.01):
                    self.genetic_evolution.evaluate_fitness(genome, accuracy)
                    break
        
        # Update cluster analyzer
        self.cluster_analyzer.add_successful_params(warp_params, accuracy)
        
        # Update reinforcement learning
        if hasattr(self, '_rl_last_params') and method.startswith('reinforcement'):
            self.reinforcement_learner.learn_from_result(
                self._rl_last_params, self._rl_last_accuracy,
                warp_params, accuracy, self._rl_attempts
            )
            self._rl_last_params = warp_params
            self._rl_last_accuracy = accuracy
        
        # Update swarm intelligence
        self.swarm_intelligence.learn_from_result(warp_params, accuracy)
        
        # Track performance by strategy
        strategy_map = {
            'neural': 'neural',
            'genetic': 'genetic', 
            'cluster': 'cluster',
            'transfer': 'transfer',
            'reinforcement': 'reinforcement',
            'swarm': 'swarm'
        }
        
        for key, strategy in strategy_map.items():
            if method.startswith(key):
                self.performance_history[strategy].append(accuracy)
                break
        
        # Update strategy weights
        self.update_strategy_weights()
        
        # Calculate advanced metrics
        genetic_fitness = self.genetic_evolution.best_genome.fitness if self.genetic_evolution.best_genome else 0.0
        
        # Get RL Q-value
        rl_q_value = 0.0
        if hasattr(self.reinforcement_learner, 'reward_history') and self.reinforcement_learner.reward_history:
            rl_q_value = np.mean(self.reinforcement_learner.reward_history[-10:]) if NUMPY_AVAILABLE else sum(self.reinforcement_learner.reward_history[-10:]) / 10
        
        # Get swarm convergence
        swarm_convergence = self.swarm_intelligence.global_best_accuracy
        
        metrics = AdvancedLearningMetrics(
            neural_confidence=neural_confidence,
            genetic_fitness=genetic_fitness,
            clustering_coherence=len(self.cluster_analyzer.clusters) / 10.0,  # Normalized
            correlation_strength=accuracy,  # Simplified
            ensemble_consensus=np.std(list(self.strategy_weights.values())) if NUMPY_AVAILABLE else 0.1,
            exploration_efficiency=accuracy * (1.0 + len(self.cluster_analyzer.successful_params) / 100.0),
            reinforcement_q_value=rl_q_value,
            swarm_convergence=swarm_convergence
        )
        
        return metrics
    
    def save_training_progress(self):
        """Save training progress to file."""
        self.training_system.save_training_data()
    
    def get_training_summary(self) -> Dict[str, Any]:
        """Get comprehensive training summary."""
        return {
            'sessions_completed': self.training_system.training_data.session_count,
            'successful_patterns': len(self.training_system.training_data.successful_parameters),
            'neural_samples': len(self.training_system.training_data.neural_training_history),
            'strategy_weights': self.strategy_weights.copy(),
            'performance_history': {k: v[-10:] for k, v in self.performance_history.items()},
            'reinforcement_q_table_size': len(self.reinforcement_learner.q_table),
            'swarm_generation': self.swarm_intelligence.generation,
            'swarm_best_fitness': self.swarm_intelligence.global_best_accuracy
        }

class LegitimateQuantumWarpAttacker:
    """
    Advanced legitimate cryptanalysis attack with sophisticated AI learning methods.
    Uses multiple ML techniques: Neural Networks, Genetic Algorithms, Clustering,
    Transfer Learning, and Ensemble Methods for maximum effectiveness.
    """
    
    def __init__(self, public_key: PublicKey, ciphertext: Ciphertext, known_plaintext: str):
        # Basic attack setup
        self.public_key = public_key
        self.ciphertext = ciphertext
        self.known_plaintext = known_plaintext
        
        # Advanced AI learning systems
        self.ensemble_coordinator = EnsembleAttackCoordinator()
        
        # Performance optimization
        self.parameter_cache = {}  # Cache tested parameters to avoid re-computation
        self.fast_rejection_filters = []
        
        # Attack statistics
        self.attempts = 0
        self.successful_attempts = 0
        self.best_accuracy = 0.0
        self.best_decryption = ""
        self.attack_log = []
        
        # Learning components (for compatibility with older methods)
        self.successful_params = []
        
        # Advanced learning metrics
        self.learning_metrics_history = []
        self.convergence_velocity = 0.0
        self.exploration_efficiency = 0.0
        
        print(f"ðŸ¤– Initializing ADVANCED AI-POWERED cryptanalysis attack")
        print(f"ðŸ“Š Available information:")
        print(f"   - Ciphertext: {len(ciphertext.quadrant_data)} quadrants")
        print(f"   - Public key: Prime p={public_key.prime}, Generator g={public_key.generator}")
        print(f"   - Known plaintext: '{known_plaintext}' ({len(known_plaintext)} chars)")
        print(f"   - Warp metrics: Temporal discontinuity = {public_key.warp_metrics.temporal_discontinuity:.4f}")
        print(f"ðŸ§  AI Learning Systems:")
        print(f"   - Neural Network Parameter Predictor")
        print(f"   - Genetic Algorithm Evolution Engine")
        print(f"   - Parameter Cluster Analysis")
        print(f"   - Transfer Learning from Previous Attacks")
        print(f"   - Reinforcement Learning Q-Table Strategy")
        print(f"   - Swarm Intelligence Particle Optimization")
        print(f"   - Ensemble Coordination & Strategy Selection")
        print(f"âš¡ Performance Optimizations:")
        print(f"   - Parameter Caching & Fast Rejection")
        print(f"   - Parallel Processing Simulation")
        print(f"   - Smart Convergence Detection")
        print(f"   - AI Training Data Persistence")
        
        # Show training data status
        if self.ensemble_coordinator.training_system.is_loaded:
            training_data = self.ensemble_coordinator.training_system.training_data
            print(f"ðŸŽ“ Pre-trained Intelligence Loaded:")
            print(f"   - Previous Sessions: {training_data.session_count}")
            print(f"   - Successful Patterns: {len(training_data.successful_parameters)}")
            print(f"   - Neural Training Samples: {len(training_data.neural_training_history)}")
            print(f"   - Strategy Knowledge: {len(training_data.strategy_effectiveness)} methods")
        else:
            print(f"ðŸ†• Starting fresh - no previous training data found")
        
        print(f"âŒ NO access to private key or internal parameters!")
    
    def fast_parameter_rejection(self, warp_params: WarpBubbleParams) -> bool:
        """Quick heuristic to reject obviously bad parameters without full testing."""
        
        # Physics-based rejection criteria
        public_metrics = self.public_key.warp_metrics
        
        # Estimate temporal discontinuity from parameters
        estimated_discontinuity = self.estimate_temporal_discontinuity(warp_params)
        
        # Reject if estimated discontinuity is too far from public value
        discontinuity_error = abs(estimated_discontinuity - public_metrics.temporal_discontinuity)
        if discontinuity_error > 0.3:  # Threshold for quick rejection
            return True  # Reject
        
        # Reject extreme parameter combinations
        if (warp_params.radius > 4.0 or warp_params.radius < 0.2 or
            warp_params.velocity > 0.95 or warp_params.velocity < 0.05 or
            warp_params.causal_disconnect < 0.6):
            return True  # Reject
        
        return False  # Don't reject, worth testing
    
    def estimate_temporal_discontinuity(self, warp_params: WarpBubbleParams) -> float:
        """Fast estimation of temporal discontinuity without full physics calculation."""
        # Simplified approximation based on key parameters
        beta = warp_params.velocity
        alpha = 1.0 / warp_params.radius
        factor = 1 - (beta ** 2) * (alpha ** 2)
        
        if factor <= 0:
            return 1.0
        
        # Simplified calculation avoiding expensive exponentiation
        approx_factor = factor ** min(10, warp_params.exponent_n / 10)
        discontinuity = 1 - approx_factor
        
        return max(0, min(1, discontinuity))
    
    def generate_warp_params_guess(self) -> Tuple[WarpBubbleParams, str]:
        """Generate parameter guess using advanced AI ensemble methods."""
        return self.ensemble_coordinator.generate_ensemble_parameters()
    
    def generate_private_key_guess(self, warp_params: WarpBubbleParams) -> PrivateKey:
        """Generate a complete private key guess from warp parameters (optimized)."""
        
        # Check cache first for performance
        param_key = self.params_to_cache_key(warp_params)
        if param_key in self.parameter_cache:
            return self.parameter_cache[param_key]
        
        # Try to reconstruct the key generation process
        physics = QuantumWarpPhysics(warp_params, PhysicsConstants())
        
        # Generate deterministic seed from warp parameters (as in original)
        seed_components = [
            int(warp_params.radius * 1000),
            int(warp_params.thickness * 1000),
            int(warp_params.velocity * 1000),
            warp_params.exponent_n,
            int(warp_params.causal_disconnect * 1000)
        ]
        deterministic_seed = sum(seed_components) % (2**32 - 1)
        
        # Calculate quadrant data with same deterministic approach
        quadrant_data = [physics.calculate_quadrant_entropy(i, deterministic_seed) for i in range(4)]
        
        # Generate private parameters using the same method as original
        original_random_state = random.getstate()
        random.seed(deterministic_seed)
        
        # Use quantum states for private parameters (same as original algorithm)
        causal_params = []
        p = self.public_key.prime  # We know the prime from public key
        
        for i in range(4):
            state_sum = sum(abs(x) for x in quadrant_data[i].quantum_state)
            param_seed = int((state_sum * 1e6 + deterministic_seed + i * 1000) % (p - 2)) + 2
            causal_params.append(param_seed)
        
        # Calculate warp metrics for temporal parameters
        warp_metrics = physics.get_physics_metrics(deterministic_seed)
        
        temporal_params = [
            int((warp_metrics.temporal_discontinuity * 1e6 + deterministic_seed) % (p - 2)) + 2,
            int((warp_metrics.quantum_entropy * 1e6 + deterministic_seed + 1000) % (p - 2)) + 2
        ]
        
        random.setstate(original_random_state)
        
        # Calculate causal elements (these should match public key if params are correct)
        g = self.public_key.generator
        causal_elements = [
            REPECryptoUtils.mod_pow(g, param, p) 
            for param in causal_params
        ]
        
        private_key = PrivateKey(
            causal_params=causal_params,
            temporal_params=temporal_params,
            prime=p,
            security_level=self.public_key.security_level,
            warp_params=warp_params,
            causal_elements=causal_elements
        )
        
        # Cache the result for performance
        self.parameter_cache[param_key] = private_key
        
        return private_key
    
    def params_to_cache_key(self, warp_params: WarpBubbleParams) -> str:
        """Convert parameters to cache key."""
        return f"{warp_params.radius:.3f}_{warp_params.thickness:.3f}_{warp_params.velocity:.3f}_{warp_params.exponent_n}_{warp_params.causal_disconnect:.3f}"
    
    def verify_key_guess(self, private_key_guess: PrivateKey) -> float:
        """Verify if a private key guess is correct by checking against public key."""
        
        # Check if computed causal elements match public key
        g = self.public_key.generator
        p = self.public_key.prime
        
        computed_causal_elements = [
            REPECryptoUtils.mod_pow(g, param, p) 
            for param in private_key_guess.causal_params
        ]
        
        # Calculate match score
        matches = 0
        for computed, public in zip(computed_causal_elements, self.public_key.causal_elements):
            if computed == public:
                matches += 1
        
        accuracy = matches / len(self.public_key.causal_elements)
        return accuracy
    
    def attempt_decryption(self, private_key_guess: PrivateKey, method: str = "ensemble") -> AttackResult:
        """Attempt to decrypt using a private key guess with advanced metrics."""
        self.attempts += 1
        
        try:
            # Use the original quantum warp decryption algorithm
            decrypted = QuantumWarpREPE.decrypt(private_key_guess, self.ciphertext, verbose=False)
            
            # Measure accuracy against known plaintext
            if len(decrypted) == len(self.known_plaintext):
                char_matches = sum(1 for a, b in zip(decrypted, self.known_plaintext) if a == b)
                plaintext_accuracy = char_matches / len(self.known_plaintext)
            else:
                # Length mismatch penalty
                length_penalty = abs(len(decrypted) - len(self.known_plaintext)) / max(len(decrypted), len(self.known_plaintext))
                plaintext_accuracy = max(0, 0.1 - length_penalty)  # Small accuracy for length mismatch
            
            # Advanced learning from this result
            learning_metrics = self.ensemble_coordinator.learn_from_result(
                private_key_guess.warp_params, plaintext_accuracy, method
            )
            self.learning_metrics_history.append(learning_metrics)
            
            # Check if this is a successful decryption
            success = plaintext_accuracy > 0.95
            
            if success:
                self.successful_attempts += 1
                self.successful_params.append(private_key_guess.warp_params)  # Store for learning
            
            if plaintext_accuracy > self.best_accuracy:
                self.best_accuracy = plaintext_accuracy
                self.best_decryption = decrypted
                
                # Update convergence velocity
                if len(self.learning_metrics_history) > 1:
                    improvement = plaintext_accuracy - self.learning_metrics_history[-2].neural_confidence
                    self.convergence_velocity = improvement
            
            result = AttackResult(
                success=success,
                decrypted_message=decrypted,
                plaintext_accuracy=plaintext_accuracy,
                key_guess=private_key_guess,
                decryption_method=method,
                confidence=plaintext_accuracy
            )
            
            self.attack_log.append(result)
            return result
            
        except Exception as e:
            # Decryption failed (wrong key)
            result = AttackResult(
                success=False,
                decrypted_message="",
                plaintext_accuracy=0.0,
                key_guess=private_key_guess,
                decryption_method=method,
                confidence=0.0
            )
            
            self.attack_log.append(result)
            return result
    
    def parallel_batch_attack(self, batch_size: int = 10) -> List[AttackResult]:
        """Simulate parallel processing by testing multiple parameters efficiently."""
        
        batch_results = []
        
        for _ in range(batch_size):
            # Generate parameter using AI ensemble
            warp_guess, method = self.generate_warp_params_guess()
            
            # Fast rejection filter
            if self.fast_parameter_rejection(warp_guess):
                continue  # Skip this parameter
            
            # Generate private key and test
            private_key_guess = self.generate_private_key_guess(warp_guess)
            result = self.attempt_decryption(private_key_guess, method)
            batch_results.append(result)
            
            # Early termination if success found
            if result.success:
                break
        
        return batch_results
    
    def adaptive_intensity_attack(self, max_attempts: int = 5000, verbose: bool = False) -> Dict[str, Any]:
        """Advanced adaptive attack with AI learning and optimization."""
        
        if verbose:
            print(f"\nðŸ¤– Starting ADVANCED AI-POWERED adaptive attack")
            print(f"ðŸ§  AI Methods: Neural Networks + Genetic Algorithms + Clustering + Transfer Learning")
            print(f"âš¡ Optimizations: Parameter Caching + Fast Rejection + Batch Processing")
            print(f"ðŸŽ¯ Max attempts: {max_attempts:,}")
            print("-" * 70)
        
        start_time = time.time()
        best_result = None
        batch_size = 10
        learning_phases = []
        
        # Track AI performance metrics
        ai_performance = {
            'neural_predictions': 0,
            'genetic_evolutions': 0,
            'cluster_analyses': 0,
            'transfer_learning': 0,
            'cache_hits': 0,
            'fast_rejections': 0
        }
        
        batch_count = 0
        while self.attempts < max_attempts:
            batch_count += 1
            
            # Adaptive batch processing
            if batch_count % 10 == 0:
                batch_size = min(20, batch_size + 2)  # Increase batch size over time
            
            # Process batch with parallel simulation
            batch_results = self.parallel_batch_attack(batch_size)
            
            # Update AI performance tracking
            for result in batch_results:
                method = result.decryption_method
                if 'neural' in method:
                    ai_performance['neural_predictions'] += 1
                elif 'genetic' in method:
                    ai_performance['genetic_evolutions'] += 1
                elif 'cluster' in method:
                    ai_performance['cluster_analyses'] += 1
                elif 'transfer' in method:
                    ai_performance['transfer_learning'] += 1
            
            # Find best result from batch
            batch_best = max(batch_results, key=lambda r: r.plaintext_accuracy) if batch_results else None
            
            if batch_best and (best_result is None or batch_best.plaintext_accuracy > best_result.plaintext_accuracy):
                best_result = batch_best
                
                if verbose and batch_best.plaintext_accuracy > 0.2:
                    print(f"ðŸš€ AI Breakthrough! Accuracy: {batch_best.plaintext_accuracy:.1%} (Method: {batch_best.decryption_method})")
                    if batch_best.plaintext_accuracy > 0.5:
                        print(f"   ðŸ“ Recovery: '{batch_best.decrypted_message[:40]}...'")
            
            # Check for success
            if best_result and best_result.success:
                if verbose:
                    print(f"\nðŸŽ‰ AI ATTACK SUCCESSFUL!")
                    print(f"ðŸ¤– Winning method: {best_result.decryption_method}")
                    print(f"âœ… Perfect decryption: '{best_result.decrypted_message}'")
                break
            
            # Progress updates with AI metrics
            if verbose and batch_count % 50 == 0:
                elapsed = time.time() - start_time
                rate = self.attempts / elapsed
                
                print(f"ðŸ“ˆ AI Progress: Batch {batch_count}, {self.attempts:,} attempts ({rate:.1f}/sec)")
                print(f"   ðŸ† Best accuracy: {self.best_accuracy:.1%}")
                print(f"   ðŸ§  AI Strategy Distribution:")
                total_ai_attempts = sum(ai_performance.values())
                if total_ai_attempts > 0:
                    for method, count in ai_performance.items():
                        if count > 0:
                            percentage = (count / total_ai_attempts) * 100
                            print(f"     â€¢ {method}: {percentage:.1f}%")
                
                # Show learning metrics
                if self.learning_metrics_history:
                    latest_metrics = self.learning_metrics_history[-1]
                    print(f"   ðŸ“Š Learning Metrics:")
                    print(f"     â€¢ Neural Confidence: {latest_metrics.neural_confidence:.3f}")
                    print(f"     â€¢ Genetic Fitness: {latest_metrics.genetic_fitness:.3f}")
                    print(f"     â€¢ Exploration Efficiency: {latest_metrics.exploration_efficiency:.3f}")
        
        elapsed_time = time.time() - start_time
        
        # Cache performance analysis
        ai_performance['cache_hits'] = len(self.parameter_cache)
        
        return {
            'total_attempts': self.attempts,
            'batch_count': batch_count,
            'best_result': best_result,
            'best_accuracy': self.best_accuracy,
            'ai_performance': ai_performance,
            'learning_metrics': self.learning_metrics_history[-10:] if self.learning_metrics_history else [],
            'elapsed_time': elapsed_time,
            'attempts_per_second': self.attempts / max(1, elapsed_time),
            'attack_success': best_result.success if best_result else False,
            'convergence_velocity': self.convergence_velocity,
            'exploration_efficiency': self.exploration_efficiency
        }
    
    def generate_guided_warp_params(self) -> WarpBubbleParams:
        """Generate parameters guided by public warp metrics."""
        metrics = self.public_key.warp_metrics
        
        # Use temporal discontinuity to guide causal_disconnect
        target_disconnect = metrics.temporal_discontinuity + random.uniform(-0.1, 0.1)
        
        # Use quantum entropy to guide other parameters
        entropy_factor = metrics.quantum_entropy / 5.0  # Normalize
        
        return WarpBubbleParams(
            radius=1.0 + entropy_factor + random.uniform(-0.5, 0.5),
            thickness=0.1 + entropy_factor * 0.1 + random.uniform(-0.03, 0.03),
            velocity=0.5 + entropy_factor * 0.3 + random.uniform(-0.2, 0.2),
            exponent_n=int(100 + entropy_factor * 50 + random.uniform(-30, 30)),
            causal_disconnect=max(0.5, min(0.99, target_disconnect))
        )
    
    def refine_successful_params(self) -> WarpBubbleParams:
        """Refine parameters around successful attempts."""
        if not self.successful_params:
            return self.generate_guided_warp_params()
        
        # Choose a successful parameter set and modify slightly
        base_params = random.choice(self.successful_params)
        
        return WarpBubbleParams(
            radius=base_params.radius + random.uniform(-0.1, 0.1),
            thickness=base_params.thickness + random.uniform(-0.01, 0.01),
            velocity=base_params.velocity + random.uniform(-0.05, 0.05),
            exponent_n=base_params.exponent_n + random.randint(-5, 5),
            causal_disconnect=base_params.causal_disconnect + random.uniform(-0.02, 0.02)
        )
    
    def local_search_around_best(self) -> WarpBubbleParams:
        """Perform local search around the best result found so far."""
        if not self.attack_log:
            return self.generate_guided_warp_params()
        
        # Find the attempt with best accuracy
        best_attempt = max(self.attack_log, key=lambda x: x.plaintext_accuracy)
        base_params = best_attempt.key_guess.warp_params
        
        # Very small variations around best
        return WarpBubbleParams(
            radius=base_params.radius + random.uniform(-0.05, 0.05),
            thickness=base_params.thickness + random.uniform(-0.005, 0.005),
            velocity=base_params.velocity + random.uniform(-0.02, 0.02),
            exponent_n=base_params.exponent_n + random.randint(-2, 2),
            causal_disconnect=base_params.causal_disconnect + random.uniform(-0.01, 0.01)
        )
    
    def brute_force_attack(self, max_attempts: int = 1000, verbose: bool = False) -> Dict[str, Any]:
        """Legitimate brute force attack trying different warp parameters."""
        
        if verbose:
            print(f"\nðŸ´â€â˜ ï¸ Starting legitimate brute force attack")
            print(f"ðŸŽ¯ Target: Recover '{self.known_plaintext}'")
            print(f"ðŸ”„ Max attempts: {max_attempts:,}")
            print(f"ðŸ“Š Method: Guess warp parameters â†’ Generate private key â†’ Decrypt")
            print("-" * 60)
        
        start_time = time.time()
        best_result = None
        breakthrough_moments = []
        
        for attempt in range(max_attempts):
            # Generate warp parameter guess
            warp_guess = self.generate_warp_params_guess()
            
            # Generate corresponding private key
            private_key_guess = self.generate_private_key_guess(warp_guess)
            
            # Verify key against public key
            key_accuracy = self.verify_key_guess(private_key_guess)
            
            # Attempt decryption
            result = self.attempt_decryption(private_key_guess)
            
            # Track best result
            if best_result is None or result.plaintext_accuracy > best_result.plaintext_accuracy:
                best_result = result
                
                if result.plaintext_accuracy > 0.1:  # Significant improvement
                    breakthrough_moments.append({
                        'attempt': attempt + 1,
                        'accuracy': result.plaintext_accuracy,
                        'key_accuracy': key_accuracy,
                        'warp_params': warp_guess
                    })
                    
                    if verbose and result.plaintext_accuracy > 0.2:
                        print(f"ðŸš€ Breakthrough at attempt {attempt + 1}!")
                        print(f"   ðŸ“Š Plaintext accuracy: {result.plaintext_accuracy:.1%}")
                        print(f"   ðŸ”‘ Key accuracy: {key_accuracy:.1%}")
                        print(f"   ðŸ“ Partial decryption: '{result.decrypted_message[:50]}...'")
            
            # Check for success
            if result.success:
                if verbose:
                    print(f"\nðŸŽ‰ ATTACK SUCCESSFUL at attempt {attempt + 1}!")
                    print(f"âœ… Perfect decryption achieved!")
                    print(f"ðŸ”“ Recovered: '{result.decrypted_message}'")
                break
            
            # Progress updates
            if verbose and attempt % 100 == 0 and attempt > 0:
                elapsed = time.time() - start_time
                rate = attempt / elapsed
                print(f"ðŸ“ˆ Progress: {attempt:,}/{max_attempts:,} attempts ({rate:.1f}/sec)")
                print(f"   ðŸ† Best accuracy so far: {self.best_accuracy:.1%}")
                if self.best_decryption:
                    print(f"   ðŸ“ Best decryption: '{self.best_decryption[:30]}...'")
        
        elapsed_time = time.time() - start_time
        
        return {
            'total_attempts': self.attempts,
            'successful_attacks': self.successful_attempts,
            'best_result': best_result,
            'best_accuracy': self.best_accuracy,
            'breakthrough_moments': breakthrough_moments,
            'elapsed_time': elapsed_time,
            'attempts_per_second': self.attempts / max(1, elapsed_time),
            'attack_success': best_result.success if best_result else False
        }
    
    def adaptive_parameter_attack(self, max_attempts: int = 2000, verbose: bool = False) -> Dict[str, Any]:
        """Adaptive attack that learns from partial successes."""
        
        if verbose:
            print(f"\nðŸ§  Starting adaptive parameter learning attack")
            print(f"ðŸŽ¯ Strategy: Learn from partial successes to narrow parameter space")
            print(f"ðŸ”„ Max attempts: {max_attempts:,}")
            print("-" * 60)
        
        start_time = time.time()
        best_result = None
        learning_phases = []
        current_phase = {'phase': 1, 'start_attempt': 1, 'best_accuracy': 0.0}
        
        for attempt in range(max_attempts):
            # Phase 1: Random exploration (first 25%)
            if attempt < max_attempts * 0.25:
                warp_guess, method = self.generate_warp_params_guess()
                attack_type = f"random_exploration_{method}"
            
            # Phase 2: Guided by public metrics (25-50%)
            elif attempt < max_attempts * 0.5:
                warp_guess = self.generate_guided_warp_params()
                attack_type = "guided_exploration"
                method = "guided"
            
            # Phase 3: Learn from successes (50-75%)
            elif attempt < max_attempts * 0.75:
                if hasattr(self, 'successful_params') and self.successful_params:
                    warp_guess = self.refine_successful_params()
                    attack_type = "success_refinement"
                    method = "refinement"
                else:
                    warp_guess = self.generate_guided_warp_params()
                    attack_type = "continued_guided"
                    method = "guided_fallback"
            
            # Phase 4: Intensive local search (75-100%)
            else:
                if best_result and best_result.plaintext_accuracy > 0.1:
                    warp_guess = self.local_search_around_best()
                    attack_type = "local_search"
                    method = "local_search"
                else:
                    warp_guess, method = self.generate_warp_params_guess()
                    attack_type = f"fallback_{method}"
            
            # Generate key and attempt decryption
            private_key_guess = self.generate_private_key_guess(warp_guess)
            key_accuracy = self.verify_key_guess(private_key_guess)
            result = self.attempt_decryption(private_key_guess, attack_type)
            
            # Update best result
            if best_result is None or result.plaintext_accuracy > best_result.plaintext_accuracy:
                best_result = result
                
                if verbose and result.plaintext_accuracy > current_phase['best_accuracy']:
                    current_phase['best_accuracy'] = result.plaintext_accuracy
                    print(f"ðŸŽ¯ Phase {current_phase['phase']} improvement: {result.plaintext_accuracy:.1%} accuracy")
                    if result.plaintext_accuracy > 0.3:
                        print(f"   ðŸ“ '{result.decrypted_message[:40]}...'")
            
            # Check for success
            if result.success:
                if verbose:
                    print(f"\nðŸŽ‰ ADAPTIVE ATTACK SUCCESSFUL!")
                    print(f"ðŸ”“ Method: {attack_type}")
                    print(f"ðŸ† Perfect decryption: '{result.decrypted_message}'")
                break
            
            # Phase transitions
            phase_boundaries = [max_attempts * 0.25, max_attempts * 0.5, max_attempts * 0.75]
            for i, boundary in enumerate(phase_boundaries):
                if attempt == int(boundary) - 1:
                    learning_phases.append(current_phase)
                    if verbose:
                        print(f"ðŸ“Š Phase {current_phase['phase']} complete: {current_phase['best_accuracy']:.1%} best accuracy")
                    current_phase = {'phase': i + 2, 'start_attempt': attempt + 1, 'best_accuracy': best_result.plaintext_accuracy if best_result else 0.0}
                    break
        
        # Add final phase
        if current_phase not in learning_phases:
            learning_phases.append(current_phase)
        
        elapsed_time = time.time() - start_time
        
        return {
            'total_attempts': self.attempts,
            'best_result': best_result,
            'best_accuracy': self.best_accuracy,
            'learning_phases': learning_phases,
            'successful_params': len(getattr(self, 'successful_params', [])),
            'elapsed_time': elapsed_time,
            'attempts_per_second': self.attempts / max(1, elapsed_time),
            'attack_success': best_result.success if best_result else False
        }
    
    def generate_guided_warp_params(self) -> WarpBubbleParams:
        """Generate parameters guided by public warp metrics."""
        metrics = self.public_key.warp_metrics
        
        # Use temporal discontinuity to guide causal_disconnect
        target_disconnect = metrics.temporal_discontinuity + random.uniform(-0.1, 0.1)
        
        # Use quantum entropy to guide other parameters
        entropy_factor = metrics.quantum_entropy / 5.0  # Normalize
        
        return WarpBubbleParams(
            radius=1.0 + entropy_factor + random.uniform(-0.5, 0.5),
            thickness=0.1 + entropy_factor * 0.1 + random.uniform(-0.03, 0.03),
            velocity=0.5 + entropy_factor * 0.3 + random.uniform(-0.2, 0.2),
            exponent_n=int(100 + entropy_factor * 50 + random.uniform(-30, 30)),
            causal_disconnect=max(0.5, min(0.99, target_disconnect))
        )
    
    def refine_successful_params(self) -> WarpBubbleParams:
        """Refine parameters around successful attempts."""
        if not self.successful_params:
            return self.generate_warp_params_guess()
        
        # Choose a successful parameter set and modify slightly
        base_params = random.choice(self.successful_params)
        
        return WarpBubbleParams(
            radius=base_params.radius + random.uniform(-0.1, 0.1),
            thickness=base_params.thickness + random.uniform(-0.01, 0.01),
            velocity=base_params.velocity + random.uniform(-0.05, 0.05),
            exponent_n=base_params.exponent_n + random.randint(-5, 5),
            causal_disconnect=base_params.causal_disconnect + random.uniform(-0.02, 0.02)
        )
    
    def local_search_around_best(self) -> WarpBubbleParams:
        """Perform local search around the best result found so far."""
        if not self.attack_log:
            return self.generate_warp_params_guess()
        
        # Find the attempt with best accuracy
        best_attempt = max(self.attack_log, key=lambda x: x.plaintext_accuracy)
        base_params = best_attempt.key_guess.warp_params
        
        # Very small variations around best
        return WarpBubbleParams(
            radius=base_params.radius + random.uniform(-0.05, 0.05),
            thickness=base_params.thickness + random.uniform(-0.005, 0.005),
            velocity=base_params.velocity + random.uniform(-0.02, 0.02),
            exponent_n=base_params.exponent_n + random.randint(-2, 2),
            causal_disconnect=base_params.causal_disconnect + random.uniform(-0.01, 0.01)
        )
    
    def focused_search_attack(self, max_attempts: int) -> Dict[str, Any]:
        """Focused search attack around the most promising results."""
        
        start_time = time.time()
        best_result = None
        
        # If we have no good results yet, fall back to adaptive search
        if not self.attack_log or max(r.plaintext_accuracy for r in self.attack_log) < 0.1:
            return self.adaptive_parameter_attack(max_attempts, verbose=False)
        
        # Find top 3 best results to focus around
        top_results = sorted(self.attack_log, key=lambda x: x.plaintext_accuracy, reverse=True)[:3]
        
        attempts_per_focus = max_attempts // len(top_results)
        
        for focus_result in top_results:
            base_params = focus_result.key_guess.warp_params
            
            # Perform intensive local search around this promising area
            for attempt in range(attempts_per_focus):
                # Generate very small variations
                variation_size = 0.02 * (1 + attempt / attempts_per_focus)  # Gradually increase variation
                
                warp_guess = WarpBubbleParams(
                    radius=base_params.radius + random.uniform(-variation_size, variation_size),
                    thickness=base_params.thickness + random.uniform(-variation_size*0.1, variation_size*0.1),
                    velocity=base_params.velocity + random.uniform(-variation_size*0.5, variation_size*0.5),
                    exponent_n=int(base_params.exponent_n + random.uniform(-variation_size*10, variation_size*10)),
                    causal_disconnect=base_params.causal_disconnect + random.uniform(-variation_size*0.2, variation_size*0.2)
                )
                
                # Ensure constraints
                warp_guess = WarpBubbleParams(
                    radius=max(0.1, min(5.0, warp_guess.radius)),
                    thickness=max(0.01, min(0.5, warp_guess.thickness)),
                    velocity=max(0.01, min(0.99, warp_guess.velocity)),
                    exponent_n=max(10, min(500, warp_guess.exponent_n)),
                    causal_disconnect=max(0.5, min(0.99, warp_guess.causal_disconnect))
                )
                
                # Test this parameter combination
                private_key_guess = self.generate_private_key_guess(warp_guess)
                result = self.attempt_decryption(private_key_guess)
                
                if best_result is None or result.plaintext_accuracy > best_result.plaintext_accuracy:
                    best_result = result
                
                # Early exit if perfect success
                if result.success:
                    break
            
            # Break if we found perfect success
            if best_result and best_result.success:
                break
        
        elapsed_time = time.time() - start_time
        
        return {
            'total_attempts': self.attempts,
            'best_result': best_result,
            'best_accuracy': self.best_accuracy,
            'elapsed_time': elapsed_time,
            'attempts_per_second': max_attempts / max(1, elapsed_time),
            'attack_success': best_result.success if best_result else False
        }

# Include all the necessary original classes and methods
# (QuantumWarpPhysics, REPECryptoUtils, QuantumWarpREPE, etc.)

class QuantumWarpPhysics:
    """Advanced quantum warp physics calculations for encryption."""
    
    def __init__(self, params: WarpBubbleParams, constants: PhysicsConstants):
        self.params = params
        self.constants = constants
        
    def calculate_warp_metric_component(self) -> float:
        """Calculate the time-time component of the warp metric tensor."""
        c_squared = self.constants.SPEED_OF_LIGHT ** 2
        beta = self.params.velocity  # v/c
        alpha = 1.0 / self.params.radius  # Characteristic length scale
        
        factor = 1 - (beta ** 2) * (alpha ** 2)
        
        if factor <= 0:
            return -c_squared
        
        try:
            metric_component = -c_squared * (factor ** self.params.exponent_n)
        except OverflowError:
            metric_component = -c_squared * math.exp(-float('inf'))
            
        return metric_component
    
    def calculate_temporal_discontinuity(self) -> float:
        """Calculate the degree of temporal discontinuity."""
        metric_component = self.calculate_warp_metric_component()
        c_squared = self.constants.SPEED_OF_LIGHT ** 2
        
        discontinuity = 1 - abs(metric_component / c_squared)
        return max(0, min(1, discontinuity))
    
    def calculate_quantum_fluctuations(self) -> Tuple[float, float]:
        """Calculate quantum fluctuations in metric and energy density."""
        h_bar = self.constants.PLANCK_CONSTANT
        G = self.constants.GRAVITATIONAL_CONSTANT
        c = self.constants.SPEED_OF_LIGHT
        R = self.params.radius
        alpha = 1.0 / R
        beta = self.params.velocity
        
        delta_g = (h_bar / (G * (c ** 3) * (R ** 3))) * (1 - alpha ** 2) * (beta ** 2)
        delta_rho = (h_bar / (c * (R ** 4))) * (1 - alpha ** 2) * (beta ** 2)
        
        return delta_g, delta_rho
    
    def calculate_energy_density(self) -> float:
        """Calculate the energy density in the warp bubble."""
        c = self.constants.SPEED_OF_LIGHT
        G = self.constants.GRAVITATIONAL_CONSTANT
        R = self.params.radius
        beta = self.params.velocity
        thickness = self.params.thickness
        
        rho = -(3 * (c ** 4)) / (32 * math.pi * G) * (1 / (R ** 2)) * ((beta ** 2) / (thickness ** 2))
        return abs(rho)
    
    def calculate_quadrant_entropy(self, quadrant_index: int, deterministic_seed: Optional[int] = None) -> QuadrantData:
        """Calculate entropy and quantum state for a specific quadrant."""
        base_entropy = self.calculate_temporal_discontinuity()
        
        if deterministic_seed is not None:
            phase = (quadrant_index * math.pi / 2) + (deterministic_seed * 0.001)
        else:
            phase = (quadrant_index * math.pi / 2) + time.time() * 0.1
        
        quadrant_factor = 0.8 + 0.4 * math.sin(phase)
        entropy = base_entropy * quadrant_factor * self.params.causal_disconnect
        causal_isolation = entropy * self.params.causal_disconnect
        
        if deterministic_seed is not None:
            seed_value = (deterministic_seed + quadrant_index * 1000) % (2**32 - 1)
        else:
            seed_value = (int(time.time() * 1000) + quadrant_index) % (2**32 - 1)
        
        if NUMPY_AVAILABLE:
            np.random.seed(seed_value)
            quantum_state = np.random.normal(0, entropy, 16)
            norm = np.linalg.norm(quantum_state)
            if norm > 0:
                quantum_state = quantum_state / norm
        else:
            random.seed(seed_value)
            quantum_state = [random.gauss(0, entropy) for _ in range(16)]
            norm = math.sqrt(sum(x**2 for x in quantum_state))
            if norm > 0:
                quantum_state = [x / norm for x in quantum_state]
        
        delta_g, delta_rho = self.calculate_quantum_fluctuations()
        fluctuation_amplitude = math.sqrt(delta_g ** 2 + delta_rho ** 2)
        
        return QuadrantData(
            entropy=entropy,
            causal_isolation=causal_isolation,
            quantum_state=quantum_state,
            fluctuation_amplitude=fluctuation_amplitude
        )
    
    def get_physics_metrics(self, deterministic_seed: Optional[int] = None) -> QuantumMetrics:
        """Get comprehensive physics metrics."""
        temporal_discontinuity = self.calculate_temporal_discontinuity()
        energy_density = self.calculate_energy_density()
        delta_g, delta_rho = self.calculate_quantum_fluctuations()
        
        quadrant_data = [self.calculate_quadrant_entropy(i, deterministic_seed) for i in range(4)]
        quadrant_entropies = [q.entropy for q in quadrant_data]
        
        total_entropy = -sum(p * math.log2(p + 1e-10) for p in quadrant_entropies if p > 0)
        
        return QuantumMetrics(
            temporal_discontinuity=temporal_discontinuity,
            energy_density=energy_density,
            quantum_entropy=total_entropy,
            quadrant_entropies=quadrant_entropies,
            metric_fluctuation=delta_g,
            density_fluctuation=delta_rho
        )

class REPECryptoUtils:
    """Enhanced cryptographic utilities for REPE system."""
    
    @staticmethod
    def is_prime(n: int, k: int = 5) -> bool:
        """Miller-Rabin primality test."""
        if n <= 1:
            return False
        if n <= 3:
            return True
        if n % 2 == 0:
            return False

        r = 0
        d = n - 1
        while d % 2 == 0:
            r += 1
            d //= 2

        for _ in range(k):
            a = random.randrange(2, n - 1)
            x = REPECryptoUtils.mod_pow(a, d, n)
            
            if x == 1 or x == n - 1:
                continue
            
            is_probable_prime = False
            for _ in range(r - 1):
                x = REPECryptoUtils.mod_pow(x, 2, n)
                if x == n - 1:
                    is_probable_prime = True
                    break
            
            if not is_probable_prime:
                return False
        
        return True

    @staticmethod
    def mod_pow(base: int, exponent: int, modulus: int) -> int:
        """Modular exponentiation: (base^exponent) % modulus."""
        if modulus == 1:
            return 0
        
        result = 1
        base = base % modulus
        
        while exponent > 0:
            if exponent % 2 == 1:
                result = (result * base) % modulus
            
            base = (base * base) % modulus
            exponent //= 2
        
        return result

    @staticmethod
    def generate_prime(bits: int, verbose: bool = False) -> int:
        """Generate a prime number with specified bit length."""
        attempts = 0
        while True:
            attempts += 1
            min_val = 2**(bits - 1)
            max_val = 2**bits - 1
            p = random.randint(min_val, max_val)
            
            if REPECryptoUtils.is_prime(p):
                return p

    @staticmethod
    def find_generator(p: int, verbose: bool = False) -> int:
        """Find a generator for the multiplicative group mod p."""
        if p == 2:
            return 1
        
        phi = p - 1
        factors = REPECryptoUtils.prime_factors(phi)
        
        for attempts in range(100):
            g = random.randint(2, p - 1)
            
            is_generator = all(
                REPECryptoUtils.mod_pow(g, phi // factor, p) != 1
                for factor in factors
            )
            
            if is_generator:
                return g
        
        return 2

    @staticmethod
    def prime_factors(n: int) -> List[int]:
        """Find prime factors of n."""
        factors = set()
        d = 2
        
        while d * d <= n:
            while n % d == 0:
                factors.add(d)
                n //= d
            d += 1
        
        if n > 1:
            factors.add(n)
        
        return list(factors)

class QuantumWarpKeyDerivation:
    """Advanced key derivation using quantum warp physics."""
    
    def __init__(self, warp_params: WarpBubbleParams, verbose: bool = False):
        self.warp_params = warp_params
        self.physics = QuantumWarpPhysics(warp_params, PhysicsConstants())
        self.verbose = verbose
        
    def derive_quantum_key(self, key_length_bits: int = 256, deterministic_seed: Optional[int] = None) -> Tuple[str, QuantumMetrics, List[QuadrantData]]:
        """Derive encryption key from quantum warp physics."""
        if deterministic_seed is None:
            seed_components = [
                int(self.warp_params.radius * 1000),
                int(self.warp_params.thickness * 1000),
                int(self.warp_params.velocity * 1000),
                self.warp_params.exponent_n,
                int(self.warp_params.causal_disconnect * 1000)
            ]
            deterministic_seed = sum(seed_components) % (2**32 - 1)
        
        metrics = self.physics.get_physics_metrics(deterministic_seed)
        quadrants = [self.physics.calculate_quadrant_entropy(i, deterministic_seed) for i in range(4)]
        
        key_sources = []
        key_sources.append(str(metrics.temporal_discontinuity))
        key_sources.append(str(metrics.energy_density))
        
        for i, quadrant in enumerate(quadrants):
            if NUMPY_AVAILABLE:
                state_bytes = quadrant.quantum_state.tobytes()
            else:
                state_str = ''.join(f"{x:.6f}" for x in quadrant.quantum_state)
                state_bytes = state_str.encode('utf-8')
            
            state_hash = hashlib.sha256(state_bytes).hexdigest()
            key_sources.append(state_hash)
        
        key_sources.extend([
            str(self.warp_params.radius),
            str(self.warp_params.thickness),
            str(self.warp_params.velocity),
            str(self.warp_params.exponent_n),
            str(self.warp_params.causal_disconnect)
        ])
        
        combined_sources = ''.join(key_sources)
        
        key_material = combined_sources
        for _ in range(1000):
            key_material = hashlib.sha512(key_material.encode()).hexdigest()
        
        key_hex = key_material[:key_length_bits // 4]
        
        return key_hex, metrics, quadrants

class QuantumWarpREPE:
    """Enhanced REPE system with quantum warp drive physics."""
    
    @staticmethod
    def key_gen(warp_params: WarpBubbleParams = None, security_level: int = 128, verbose: bool = False) -> KeyPair:
        """Generate REPE key pair using quantum warp physics."""
        
        if warp_params is None:
            warp_params = WarpBubbleParams()
        
        prime_bits = {128: 20, 192: 25, 256: 30}.get(security_level, 20)
        
        seed_components = [
            int(warp_params.radius * 1000),
            int(warp_params.thickness * 1000),
            int(warp_params.velocity * 1000),
            warp_params.exponent_n,
            int(warp_params.causal_disconnect * 1000)
        ]
        deterministic_seed = sum(seed_components) % (2**32 - 1)
        
        key_derivation = QuantumWarpKeyDerivation(warp_params, verbose)
        quantum_key, warp_metrics, quadrant_data = key_derivation.derive_quantum_key(256, deterministic_seed)
        
        random.seed(int(quantum_key[:16], 16))
        p = REPECryptoUtils.generate_prime(prime_bits, verbose)
        g = REPECryptoUtils.find_generator(p, verbose)
        
        original_random_state = random.getstate()
        random.seed(deterministic_seed)
        
        causal_params = []
        for i in range(4):
            state_sum = sum(abs(x) for x in quadrant_data[i].quantum_state)
            param_seed = int((state_sum * 1e6 + deterministic_seed + i * 1000) % (p - 2)) + 2
            causal_params.append(param_seed)
        
        temporal_params = [
            int((warp_metrics.temporal_discontinuity * 1e6 + deterministic_seed) % (p - 2)) + 2,
            int((warp_metrics.quantum_entropy * 1e6 + deterministic_seed + 1000) % (p - 2)) + 2
        ]
        
        random.setstate(original_random_state)
        
        causal_elements = [
            REPECryptoUtils.mod_pow(g, param, p) 
            for param in causal_params
        ]
        
        temporal_elements = [
            REPECryptoUtils.mod_pow(g, param, p) 
            for param in temporal_params
        ]
        
        private_key = PrivateKey(
            causal_params=causal_params,
            temporal_params=temporal_params,
            prime=p,
            security_level=security_level,
            warp_params=warp_params,
            causal_elements=causal_elements
        )
        
        public_key = PublicKey(
            causal_elements=causal_elements,
            temporal_elements=temporal_elements,
            prime=p,
            generator=g,
            security_level=security_level,
            warp_metrics=warp_metrics
        )
        
        return KeyPair(private_key, public_key)

    @staticmethod
    def encrypt(public_key: PublicKey, message: str, verbose: bool = False) -> Ciphertext:
        """Encrypt message using quantum warp REPE algorithm."""
        
        data = message.encode('utf-8')
        
        quadrants = QuantumWarpREPE.split_message_quantum(data, public_key.warp_metrics, verbose)
        
        encrypted_quadrants = []
        for i, quadrant in enumerate(quadrants):
            quadrant_key = QuantumWarpREPE.derive_quadrant_key(
                public_key.causal_elements[i], 
                public_key.warp_metrics.quadrant_entropies[i],
                verbose
            )
            
            encrypted = bytes(
                byte ^ quadrant_key[j % len(quadrant_key)]
                for j, byte in enumerate(quadrant)
            )
            
            encrypted_quadrants.append(encrypted)
        
        warp_signature = QuantumWarpREPE.generate_warp_signature(data, public_key.warp_metrics, verbose)
        temporal_tag = QuantumWarpREPE.generate_quantum_temporal_tag(data, public_key.warp_metrics, verbose)
        
        ciphertext = Ciphertext(
            quadrant_data=encrypted_quadrants,
            temporal_data=temporal_tag,
            warp_signature=warp_signature
        )
        
        return ciphertext

    @staticmethod
    def decrypt(private_key: PrivateKey, ciphertext: Ciphertext, verbose: bool = False) -> str:
        """Decrypt message using quantum warp REPE algorithm."""
        
        key_derivation = QuantumWarpKeyDerivation(private_key.warp_params, verbose)
        
        seed_components = [
            int(private_key.warp_params.radius * 1000),
            int(private_key.warp_params.thickness * 1000), 
            int(private_key.warp_params.velocity * 1000),
            private_key.warp_params.exponent_n,
            int(private_key.warp_params.causal_disconnect * 1000)
        ]
        deterministic_seed = sum(seed_components) % (2**32 - 1)
        
        _, warp_metrics, _ = key_derivation.derive_quantum_key(256, deterministic_seed)
        
        public_elements = private_key.causal_elements
        
        decrypted_quadrants = []
        for i, quadrant_data in enumerate(ciphertext.quadrant_data):
            quadrant_key = QuantumWarpREPE.derive_quadrant_key(
                public_elements[i], 
                warp_metrics.quadrant_entropies[i],
                verbose
            )
            
            decrypted = bytes(
                byte ^ quadrant_key[j % len(quadrant_key)]
                for j, byte in enumerate(quadrant_data)
            )
            
            decrypted_quadrants.append(decrypted)
        
        combined_data = QuantumWarpREPE.combine_quantum_quadrants(decrypted_quadrants, verbose)
        
        is_valid = QuantumWarpREPE.verify_warp_signature(
            combined_data, 
            ciphertext.warp_signature, 
            warp_metrics, 
            verbose
        )
        
        try:
            decrypted_message = combined_data.decode('utf-8')
        except UnicodeDecodeError:
            decrypted_message = combined_data.decode('utf-8', errors='replace')
        
        return decrypted_message

    @staticmethod
    def split_message_quantum(data: bytes, warp_metrics: QuantumMetrics, verbose: bool = False) -> List[bytes]:
        """Split message into causally disconnected quadrants."""
        quadrants = [bytearray() for _ in range(4)]
        
        for i, byte in enumerate(data):
            quadrant_index = i % 4
            quadrants[quadrant_index].append(byte)
        
        return [bytes(q) for q in quadrants]

    @staticmethod
    def combine_quantum_quadrants(quadrants: List[bytes], verbose: bool = False) -> bytes:
        """Combine causally disconnected quadrants back into message."""
        max_length = max(len(q) for q in quadrants)
        combined = bytearray()
        
        for i in range(max_length):
            for j, quadrant in enumerate(quadrants):
                if i < len(quadrant):
                    combined.append(quadrant[i])
        
        return bytes(combined)

    @staticmethod
    def derive_quadrant_key(causal_element: int, quantum_entropy: float, verbose: bool = False) -> bytes:
        """Derive encryption key for a specific quadrant."""
        key_source = f"{causal_element}:{quantum_entropy}"
        
        key_material = key_source
        for _ in range(100):
            key_material = hashlib.sha256(key_material.encode()).hexdigest()
        
        return key_material.encode()[:32]

    @staticmethod
    def generate_warp_signature(data: bytes, warp_metrics: QuantumMetrics, verbose: bool = False) -> bytes:
        """Generate quantum warp signature for message integrity."""
        signature_data = data + str(warp_metrics.temporal_discontinuity).encode()
        signature_data += str(warp_metrics.quantum_entropy).encode()
        signature_data += str(warp_metrics.energy_density).encode()
        
        signature = hashlib.sha512(signature_data).digest()
        for i in range(10):
            quantum_salt = str(warp_metrics.metric_fluctuation + i).encode()
            signature = hashlib.sha512(signature + quantum_salt).digest()
        
        return signature

    @staticmethod
    def verify_warp_signature(data: bytes, signature: bytes, warp_metrics: QuantumMetrics, verbose: bool = False) -> bool:
        """Verify quantum warp signature."""
        expected_signature = QuantumWarpREPE.generate_warp_signature(data, warp_metrics, False)
        return signature == expected_signature

    @staticmethod
    def generate_quantum_temporal_tag(data: bytes, warp_metrics: QuantumMetrics, verbose: bool = False) -> bytes:
        """Generate enhanced temporal tag with quantum properties."""
        timestamp = int(time.time())
        
        data_hash = hashlib.sha256(data).digest()
        temporal_factor = warp_metrics.temporal_discontinuity
        quantum_factor = warp_metrics.quantum_entropy
        
        tag_data = data_hash + struct.pack('d', temporal_factor) + struct.pack('d', quantum_factor)
        tag_data += struct.pack('Q', timestamp)
        
        return hashlib.sha256(tag_data).digest()

def demonstrate_legitimate_attack():
    """Demonstrate a legitimate cryptanalysis attack that doesn't cheat."""
    
    print("ðŸ´â€â˜ ï¸ LEGITIMATE QUANTUM WARP CRYPTANALYSIS ATTACK")
    print("=" * 80)
    print("This attack only uses information available to a real attacker:")
    print("- Ciphertext")
    print("- Public key") 
    print("- Known plaintext (known-plaintext attack scenario)")
    print("âŒ NO access to private key or internal secrets!")
    print("ðŸ”„ UNLIMITED ATTEMPTS until complete message recovery!")
    print()
    
    # Set up the encryption system
    warp_params = WarpBubbleParams(
        radius=1.5,
        thickness=0.08,
        velocity=0.7,
        exponent_n=150,
        causal_disconnect=0.9
    )
    
    message = "Attack this quantum encryption!"
    print(f"ðŸŽ¯ Target Message: '{message}'")
    
    # Generate keys and encrypt (legitimate system)
    print("\nðŸ” Setting up legitimate encryption...")
    key_pair = QuantumWarpREPE.key_gen(warp_params, security_level=128, verbose=False)
    ciphertext = QuantumWarpREPE.encrypt(key_pair.public_key, message, verbose=False)
    
    # Verify legitimate decryption works
    decrypted = QuantumWarpREPE.decrypt(key_pair.private_key, ciphertext, verbose=False)
    print(f"âœ… Legitimate decryption: '{decrypted}'")
    print(f"âœ… Encryption system working: {message == decrypted}")
    
    # Create legitimate attacker (NO access to private key!)
    print(f"\nðŸ´â€â˜ ï¸ Initializing legitimate attacker...")
    attacker = LegitimateQuantumWarpAttacker(
        public_key=key_pair.public_key,
        ciphertext=ciphertext,
        known_plaintext=message
    )
    
    # UNLIMITED ATTACK UNTIL SUCCESS
    print(f"\nðŸš€ BEGINNING UNLIMITED PERSISTENT ATTACK")
    print("=" * 80)
    print("ðŸŽ¯ MISSION: Complete message recovery through persistent cryptanalysis")
    print("ðŸ”„ Strategy: Adaptive learning with unlimited attempts")
    print("âš ï¸  Note: Press Ctrl+C to interrupt if needed")
    print("=" * 80)
    
    attack_phases = []
    total_attempts = 0
    best_accuracy = 0.0
    attack_round = 0
    intensity_level = 1
    
    # Track overall progress
    breakthrough_history = []
    learning_progression = []
    
    try:
        while True:
            attack_round += 1
            
            # Determine attack intensity (increases over time)
            if attack_round % 5 == 0:
                intensity_level += 1
            
            attempts_this_round = min(2000, 500 * intensity_level)
            
            print(f"\nðŸ”„ ATTACK ROUND {attack_round}")
            print(f"âš¡ Intensity Level: {intensity_level}")
            print(f"ðŸŽ¯ Attempts this round: {attempts_this_round:,}")
            print("-" * 60)
            
            # Alternate between different attack strategies
            if attack_round % 3 == 1:
               # Run advanced AI attack (use the new AI method instead of old ones)
                print(f"ðŸ¤– Phase: Advanced AI Ensemble Attack")
                round_results = attacker.adaptive_intensity_attack(max_attempts=attempts_this_round, verbose=False)
                phase_type = "ai_ensemble"
            elif attack_round % 3 == 2:
                # Adaptive learning phase
                print(f"ðŸ§  Phase: Adaptive Parameter Learning")
                round_results = attacker.adaptive_parameter_attack(max_attempts=attempts_this_round, verbose=False)
                phase_type = "adaptive_learning"
            else:
                # Focused search around best results
                print(f"ðŸŽ¯ Phase: Focused Search Around Best Results")
                round_results = attacker.focused_search_attack(attempts_this_round)
                phase_type = "focused_search"
            
            # Update overall statistics
            round_attempts = round_results['total_attempts'] - total_attempts
            total_attempts = round_results['total_attempts']
            current_best = round_results['best_accuracy']
            
            # Track progress
            learning_progression.append({
                'round': attack_round,
                'phase': phase_type,
                'attempts': round_attempts,
                'cumulative_attempts': total_attempts,
                'best_accuracy': current_best,
                'improvement': current_best - best_accuracy if current_best > best_accuracy else 0
            })
            
            # Check for breakthrough
            if current_best > best_accuracy:
                improvement = current_best - best_accuracy
                best_accuracy = current_best
                
                breakthrough = {
                    'round': attack_round,
                    'phase': phase_type,
                    'accuracy': current_best,
                    'improvement': improvement,
                    'total_attempts': total_attempts,
                    'message': round_results['best_result'].decrypted_message if round_results['best_result'] else ""
                }
                breakthrough_history.append(breakthrough)
                
                print(f"ðŸš€ BREAKTHROUGH! New best accuracy: {current_best:.1%}")
                if improvement > 0.1:  # Significant improvement
                    print(f"ðŸ“ˆ Major improvement: +{improvement:.1%}")
                
                if round_results['best_result']:
                    recovered = round_results['best_result'].decrypted_message
                    print(f"ðŸ“ Current best recovery: '{recovered[:40]}{'...' if len(recovered) > 40 else ''}'")
                    
                    # Show character-by-character comparison for high accuracy
                    if current_best > 0.5:
                        print(f"ðŸŽ¯ Target:  '{message}'")
                        print(f"ðŸ“ Actual:  '{recovered}'")
                        
                        # Show specific differences
                        if len(recovered) == len(message):
                            differences = []
                            for i, (t, a) in enumerate(zip(message, recovered)):
                                if t != a:
                                    differences.append(f"pos {i}: '{t}' â†’ '{a}'")
                            
                            if differences:
                                print(f"âŒ Differences: {', '.join(differences[:3])}")
                                if len(differences) > 3:
                                    print(f"   ... and {len(differences) - 3} more")
                            else:
                                print(f"âœ… Perfect character match!")
            
            # Check for perfect success
            if round_results['attack_success']:
                print(f"\nðŸŽ‰ðŸŽ‰ðŸŽ‰ PERFECT ATTACK SUCCESS! ðŸŽ‰ðŸŽ‰ðŸŽ‰")
                print(f"âœ… Complete message recovery achieved!")
                print(f"ðŸ”“ Perfect decryption: '{round_results['best_result'].decrypted_message}'")
                print(f"ðŸ”„ Attack rounds required: {attack_round}")
                print(f"ðŸŽ¯ Total attempts: {total_attempts:,}")
                
                attack_phases.append({
                    'round': attack_round,
                    'phase': phase_type,
                    'result': round_results,
                    'success': True
                })
                break
            
            # Store phase results
            attack_phases.append({
                'round': attack_round,
                'phase': phase_type,
                'result': round_results,
                'success': False
            })
            
            # Progress summary
            print(f"ðŸ“Š Round {attack_round} Summary:")
            print(f"   ðŸŽ¯ Attempts this round: {round_attempts:,}")
            print(f"   ðŸ“ˆ Round best accuracy: {current_best:.1%}")
            print(f"   ðŸ† Overall best: {best_accuracy:.1%}")
            print(f"   ðŸ”„ Cumulative attempts: {total_attempts:,}")
            print(f"   âš¡ Attack intensity: Level {intensity_level}")
            
            # Show learning trend
            if len(learning_progression) > 1:
                recent_progress = [p['best_accuracy'] for p in learning_progression[-3:]]
                if len(recent_progress) >= 2:
                    trend = recent_progress[-1] - recent_progress[0]
                    print(f"   ðŸ“ˆ Recent trend: {trend:+.1%} over last {len(recent_progress)} rounds")
            
            # Adaptive intensity increase if progress stalls
            if attack_round > 10:
                recent_best = [p['best_accuracy'] for p in learning_progression[-5:]]
                if len(recent_best) == 5:
                    progress_rate = max(recent_best) - min(recent_best)
                    if progress_rate < 0.01:  # Less than 1% progress in 5 rounds
                        intensity_level += 2
                        print(f"ðŸ†˜ Progress stalled - boosting intensity to level {intensity_level}!")
            
            # Show major milestones
            if current_best >= 0.25 and not any(b['accuracy'] >= 0.25 for b in breakthrough_history[:-1]):
                print(f"ðŸ… MILESTONE: 25% accuracy achieved!")
            elif current_best >= 0.5 and not any(b['accuracy'] >= 0.5 for b in breakthrough_history[:-1]):
                print(f"ðŸ… MILESTONE: 50% accuracy achieved!")
            elif current_best >= 0.75 and not any(b['accuracy'] >= 0.75 for b in breakthrough_history[:-1]):
                print(f"ðŸ… MILESTONE: 75% accuracy achieved!")
            elif current_best >= 0.9 and not any(b['accuracy'] >= 0.9 for b in breakthrough_history[:-1]):
                print(f"ðŸ… MILESTONE: 90% accuracy achieved - very close!")
    
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  ATTACK INTERRUPTED BY USER")
        print(f"ðŸ”„ Completed {attack_round} attack rounds")
        print(f"ðŸŽ¯ Total attempts: {total_attempts:,}")
        print(f"ðŸ† Best accuracy achieved: {best_accuracy:.1%}")
        if attacker.best_decryption:
            print(f"ðŸ“ Best recovery: '{attacker.best_decryption[:50]}{'...' if len(attacker.best_decryption) > 50 else ''}'")
        
        # Return partial results
        return {
            'security_level': "INTERRUPTED",
            'best_accuracy': best_accuracy,
            'total_attempts': total_attempts,
            'attack_rounds': attack_round,
            'attack_phases': attack_phases,
            'breakthrough_history': breakthrough_history,
            'learning_progression': learning_progression,
            'attack_success': False,
            'interrupted': True
        }
    
    # SUCCESS - Compile final results
    print(f"\n" + "ðŸ†" * 20 + " ATTACK SUCCESSFUL " + "ðŸ†" * 20)
    print(f"âœ… COMPLETE MESSAGE RECOVERY: 100% accuracy achieved!")
    print(f"ðŸ”„ Attack rounds required: {attack_round}")
    print(f"ðŸŽ¯ Total attempts: {total_attempts:,}")
    print(f"âš¡ Final intensity level: {intensity_level}")
    
    # Show learning progression
    print(f"\nðŸ“ˆ LEARNING PROGRESSION:")
    milestone_rounds = [1, 5, 10, 25, 50, 100]
    for milestone in milestone_rounds:
        if milestone <= len(learning_progression):
            entry = learning_progression[milestone - 1]
            print(f"  Round {milestone:3d}: {entry['best_accuracy']:.1%} accuracy ({entry['phase']})")
        if milestone >= len(learning_progression):
            break
    
    if len(learning_progression) > 10:
        print(f"  ...")
        final_entry = learning_progression[-1]
        print(f"  Round {len(learning_progression):3d}: {final_entry['best_accuracy']:.1%} accuracy - PERFECT!")
    
    # Show breakthrough moments
    print(f"\nðŸš€ BREAKTHROUGH HISTORY:")
    for i, breakthrough in enumerate(breakthrough_history[-5:], 1):  # Show last 5
        print(f"  #{i}: Round {breakthrough['round']} - {breakthrough['accuracy']:.1%} accuracy (+{breakthrough['improvement']:.1%})")
    
    # Attack strategy effectiveness
    print(f"\nðŸŽ¯ ATTACK STRATEGY EFFECTIVENESS:")
    phase_stats = {}
    for phase in attack_phases:
        phase_type = phase['phase']
        if phase_type not in phase_stats:
            phase_stats[phase_type] = {'rounds': 0, 'best_accuracy': 0, 'breakthroughs': 0}
        
        phase_stats[phase_type]['rounds'] += 1
        if phase['result']['best_accuracy'] > phase_stats[phase_type]['best_accuracy']:
            phase_stats[phase_type]['best_accuracy'] = phase['result']['best_accuracy']
        
        # Count breakthroughs in this phase
        for breakthrough in breakthrough_history:
            if breakthrough['round'] == phase['round'] and breakthrough['phase'] == phase_type:
                phase_stats[phase_type]['breakthroughs'] += 1
    
    for phase_type, stats in phase_stats.items():
        print(f"  â€¢ {phase_type}: {stats['rounds']} rounds, {stats['best_accuracy']:.1%} best, {stats['breakthroughs']} breakthroughs")
    
    # Final security assessment
    print(f"\nðŸ›¡ï¸ FINAL SECURITY ASSESSMENT:")
    print(f"   Security Level: BROKEN")
    print(f"   Assessment: âŒ Encryption successfully broken by persistent legitimate attack")
    print(f"   Attack Success: âœ… YES - Perfect message recovery")
    print(f"   Persistence Required: {attack_round} rounds of adaptive learning")
    print(f"   Total Cryptanalysis Effort: {total_attempts:,} parameter combinations tested")
    
    # Theoretical analysis
    prime_bits = len(str(key_pair.private_key.prime)) * math.log2(10)
    theoretical_keyspace = 2 ** prime_bits
    coverage = total_attempts / theoretical_keyspace
    
    print(f"\nðŸ”¬ THEORETICAL ANALYSIS:")
    print(f"   Prime size: ~{prime_bits:.0f} bits")
    print(f"   Theoretical keyspace: ~2^{prime_bits:.0f}")
    print(f"   Search coverage: {coverage:.2e} of keyspace")
    print(f"   Success demonstrates: Parameter space sufficiently constrained")
    print(f"   Attack methodology: Persistent adaptive parameter search")
    
    return {
        'security_level': "BROKEN",
        'best_accuracy': 1.0,  # Perfect recovery
        'total_attempts': total_attempts,
        'attack_rounds': attack_round,
        'attack_phases': attack_phases,
        'breakthrough_history': breakthrough_history,
        'learning_progression': learning_progression,
        'attack_success': True,
        'final_intensity': intensity_level
    }

if __name__ == "__main__":
    # Set random seed for reproducible results in demo
    random.seed(42)
    if NUMPY_AVAILABLE:
        np.random.seed(42)
    
    print("ðŸ¤– UNLIMITED AI-POWERED PERSISTENT CRYPTANALYSIS")
    print("=" * 80)
    print("ðŸŽ¯ This attack uses advanced AI to break quantum encryption")
    print("ðŸ§  AI Arsenal: Neural Networks + Genetic Algorithms + ML Clustering + Transfer Learning")
    print("ðŸ†• NEW: Reinforcement Learning + Swarm Intelligence + AI Training Persistence")
    print("âš¡ Optimizations: Parameter Caching + Fast Rejection + Parallel Batching")
    print("ðŸŽ“ Intelligence: Pre-trained models load automatically for enhanced performance")
    print("ðŸ”„ No attempt limits - AI learns and adapts until complete success")
    print("âš ï¸  Press Ctrl+C to interrupt the AI attack if needed")
    print("=" * 80)
    
    # Run unlimited AI-powered attack
    results = demonstrate_legitimate_attack()
    
    if results.get('interrupted'):
        print(f"\nðŸ’” AI attack was interrupted before completion")
        print(f"ðŸ”„ AI Progress: {results['attack_rounds']} rounds completed")
        print(f"ðŸŽ¯ Best AI result: {results['best_accuracy']:.1%} message recovery")
        print(f"ðŸ“Š Total AI effort: {results['total_attempts']:,} attempts")
        print(f"ðŸ¤– AI methods tested: {results.get('ai_methods_used', 'Multiple')}")
    else:
        print(f"\nðŸŽ‰ COMPLETE AI CRYPTANALYSIS SUCCESS!")
        print(f"ðŸ¤– Advanced AI systems have completely broken the quantum warp encryption!")
        print(f"ðŸ”„ AI attack rounds required: {results['attack_rounds']}")
        print(f"ðŸ“Š Total AI cryptanalysis effort: {results['total_attempts']:,} attempts")
        print(f"ðŸ§  Winning AI method: {results.get('winning_ai_method', 'AI Ensemble')}")
        
        if 'training_summary' in results:
            training = results['training_summary']
            print(f"ðŸŽ“ AI learned {training['successful_patterns']} new patterns")
            print(f"ðŸ“ˆ Reinforcement Q-table: {training['reinforcement_q_table_size']} states")
            print(f"ðŸ Swarm intelligence: Generation {training['swarm_generation']}")
        
        print(f"ðŸ’¡ This demonstrates that advanced AI with persistent learning can")
        print(f"   systematically break even sophisticated quantum encryption through:")
        print(f"   â€¢ Intelligent parameter space exploration")
        print(f"   â€¢ Machine learning pattern recognition")
        print(f"   â€¢ Reinforcement learning strategy optimization")
        print(f"   â€¢ Swarm intelligence collaborative search")
        print(f"   â€¢ Persistent training data accumulation")
    
    print(f"\nðŸ›¡ï¸ Final security assessment: {results['security_level']}")
    print(f"ðŸ Advanced AI cryptanalysis demonstration complete!")
    print(f"\nðŸ¤– AI METHODS SHOWCASE:")
    print(f"âœ… Neural Network Parameter Prediction - Learns optimal parameter patterns")
    print(f"âœ… Genetic Algorithm Evolution - Evolves successful parameter combinations")  
    print(f"âœ… Machine Learning Clustering - Discovers parameter clusters")
    print(f"âœ… Transfer Learning - Applies knowledge from previous attacks")
    print(f"âœ… Reinforcement Learning - Q-learning strategy optimization")
    print(f"âœ… Swarm Intelligence - Particle swarm collaborative exploration")
    print(f"âœ… Ensemble Coordination - Intelligently combines all AI methods")
    print(f"âœ… Performance Optimization - Caching, fast rejection, batch processing")
    print(f"âœ… Training Persistence - Accumulates intelligence across sessions")
    print(f"âœ… Adaptive Learning - Continuously improves strategy based on results")
    
    print(f"\nðŸŽ“ TRAINING SYSTEM FEATURES:")
    print(f"ðŸ“ Training file: quantum_ai_training.pkl (automatically saved/loaded)")
    print(f"ðŸ§  Persistent neural network knowledge")
    print(f"ðŸ§¬ Genetic algorithm population memory")
    print(f"ðŸŽ¯ Successful parameter pattern database")
    print(f"ðŸ“Š Strategy effectiveness tracking")
    print(f"ðŸ† Cross-session breakthrough history")
    print(f"ðŸ”„ Next run will be faster and smarter!")
    
    if os.path.exists("quantum_ai_training.pkl"):
        print(f"\nðŸ’¾ Training data saved! Next attack will benefit from learned intelligence.")
    else:
        print(f"\nðŸ†• First run complete - training data will be available for future attacks.")
